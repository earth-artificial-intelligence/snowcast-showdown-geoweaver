[{
  "history_id" : "256nifud60u",
  "history_input" : "import gc\nimport numpy as np\nimport torch\nfrom models_init import calcdevice\nfrom models_apply import applymodels\n\ndef getests (inputs, result, factor=1., select=None, region=None):\n    e = inputs['target'][...,0]-result*factor\n    e1 = e[torch.isfinite(e)].detach().cpu()\n    est = np.round([e1.mean().item(), np.sqrt((e1*e1).mean()).item()],4)\n    if select is not None:\n        e = e[select]\n    if region is not None:\n        e = e[:,region]\n    e = e[torch.isfinite(e)].detach().cpu()\n    est = np.hstack((est,np.round([e.mean().item(), np.sqrt((e*e).mean()).item()],4)))\n    return est\n\ndef quantile(vals, w, q=0.5):\n    s,perm = torch.sort(vals, -1)\n    ws = torch.gather(w.expand_as(vals),-1,perm)\n    ws = torch.cumsum(ws,-1)\n    ws.div_(ws[...,-1:])\n    c = (ws<q).sum(-1,keepdim=True).clamp_(ws.shape[-1]-2)\n    w1 = torch.gather(ws,-1,c)\n    w2 = torch.gather(ws,-1,c+1)\n    return ((torch.gather(s,-1,c)*(w2-q) + torch.gather(s,-1,c+1)*(q-w1))/(w2-w1))[...,0]*w.sum(-1)\n\n# result = (rets1*w[:,None]).sum(-1)\n# result = quantile(rets1, w[:,None])\n# w = rets - torch.nan_to_num (x['target'])\n# L2 = 1.\n# w = 1./ ((w*w).clamp(max=10.).sum(1)/okx.sum(1) + L2*L2)\n# # w.mul_((w<w.max(-1,keepdim=True)[0])&(w>w.min(-1,keepdim=True)[0]))\n# w.div_(w.sum(-1,keepdim=True))\n# r = (rets*w[:,None]).sum(-1,keepdim=True)\n# w.mul_ ((r*torch.nan_to_num (x['target'])).sum(1)/(r*r).sum(1)).mul_ (0.825)\n# result = (rets1*w[:,None]).sum(-1)\n# models.getests (inputs['test'], result, select=spring)\n# trg = inputs['test']['target'][...,0]\n# ok  = torch.isfinite(trg-result); r = result[ok]\n# bfactor = ((trg[ok]*r).sum()/(r*r).sum()).item()\n# models.getests (inputs['test'], result, bfactor, select=spring)\n\n# xv = inputs['test']['xval'].clone()\n# inputs['test']['xval'][bad] = np.nan\n# rets11 = models.applymodels (inputs['test'], modelslist, average=False).clamp_(min=0.)\n# inputs['test']['xval'] = xv\n\ndef inference (inputs, models, dates, lab='', smart=True, L2=1., factor=1., device=calcdevice,\n               calcsd=False, noemb=False, nousest=True, print=print):\n    gc.collect()\n    torch.cuda.empty_cache()\n    with torch.no_grad():\n        if smart is not None and 'ylo' in inputs:\n            x = {key: inputs[key].detach() for key in inputs if key[0] == 'x'}\n            x['yid'] = x['xid'] = torch.zeros_like(x['xlo'])\n            x['target'] = x['xval'][...,:1].clone()\n            trg = x['target'].clone()\n            okx = torch.isfinite(trg)\n            rets = applymodels (x, models, average=False, device=device)*okx            \n            w = rets - torch.nan_to_num (trg) \n            w = 1./ ((w*w).sum(1)/okx.sum(1) + L2*L2)\n            # w = 1./ (torch.abs(w).sum(1)/okx.sum(1) + L2)\n            # kf = w.max(-1,keepdim=True)[0]/w.min(-1,keepdim=True)[0]\n            # print ([kf.max(), kf.mean(), kf.min()])\n            # w.mul_((w<w.max(-1,keepdim=True)[0])&(w>w.min(-1,keepdim=True)[0]))\n            w.div_(w.sum(-1,keepdim=True))\n            r = (rets*w[:,None]).sum(-1,keepdim=True)\n            # if qc:\n            #     bad = ((trg[...,0]<rets.min(-1)[0]-3.)&(trg[...,0]>3.)) | (trg[...,0]>rets.max(-1)[0]+3.)\n            #     print(f\"qc #{bad[torch.isfinite(trg)[...,0]].float().mean().item()*100.:.5}%\")\n            w.mul_ ((r*torch.nan_to_num (trg)).sum(1)/(r*r).sum(1))\n            # if nousest:\n            w.mul_ (0.875) #Magic constant\n            # else:\n            #     w.mul_ (0.925) #Magic constant\n            del x, rets, okx\n            gc.collect()\n            torch.cuda.empty_cache()\n            # if qc:\n            #     xv = inputs['xval'].clone()\n            #     inputs['xval'][bad] = np.nan\n            w = w[:,None]\n            if noemb and 'yemb' in inputs:\n                ws = w.sum(-1,keepdim=True)\n                w = w.expand(-1,inputs['yval'].shape[1],-1)\n                noembmodels = torch.tensor([models[m].embedding<=0 for m in models], device=w.device)\n                w = w*((inputs['yemb'][0,:,None]>0)|noembmodels)\n                w = w/w.sum(-1,keepdim=True)*ws\n            if nousest:\n                print('Noemb mult 0.85')\n                w = w*(1.-0.15*(inputs['yemb'][0,:,None]==0))\n            result = applymodels (inputs, models, average=w, device=device, calcsd=calcsd).clamp_(min=0.)\n            # if qc:\n            #     inputs['xval'] = xv\n        else:\n            result = applymodels (inputs, models, device=device, calcsd=calcsd).clamp_(min=0.)\n            result.mul_ (0.9)\n        # result [result<0.01] = 0.\n    if 'target' in inputs:\n        spring = np.array([d.month*100+d.day for d in dates])\n        spring = (spring>=215)&(spring<=701)#&np.array([d.year>=2021 for d in dates])\n        spring = torch.tensor(spring, device=result.device)\n        # spring = None\n        exper = torch.isfinite(inputs['target'][...,0]).float().mean(0)<0.2\n        ests = getests (inputs, result, select=spring)\n        msg = lab+(f' L2={L2}' if smart else '')+(' sd' if calcsd else '')+('' if nousest else '|new|')+f' raw={ests}'        \n        ests = getests (inputs, result, select=spring, region=exper)\n        msg += f'{ests[2:]}'\n        if factor != 1.:\n            ests = getests (inputs, result, factor, select=spring)\n            msg += f' factor={factor:.4}:{ests}'        \n        trg = inputs['target'][...,0]\n        ok  = torch.isfinite(trg-result); r = result[ok]\n        bfactor = ((trg[ok]*r).sum()/(r*r).sum()).item()\n        ests = getests (inputs, result, bfactor, select=spring)\n        msg += f' bfactor={bfactor:.4}:{ests}'\n        ests = getests (inputs, result, bfactor, select=spring, region=exper)\n        msg += f'{ests[2:]}'\n        print('Estimations: '+ msg)\n    result = result.mul_(factor) #.to(maindevice)\n    return result\n\ndef test(inputs, models, dates, lab='', iyear='', device=calcdevice, calcsd=False, print=print, nousest=True):\n    models = {key: models[key].to(device) for key in models}\n    if len(models) == 1:\n        calcsd = False\n    r = {mode: inference (inputs[mode], models, dates[mode], lab=lab+'_'+mode+iyear, smart=True, factor=1., device=device, calcsd=calcsd, print=print, nousest=nousest) for mode in inputs}\n    if 'test' in inputs:\n        inference (inputs['test'], models, dates['test'], lab=lab+'_test'+iyear, smart=None, device=device, calcsd=calcsd, print=print, nousest=nousest)\n        # if len(models) > 1:\n        #     inference (inputs['test'], models, dates['test'], lab=lab+'_test'+iyear, smart=None, device=device, calcsd=~calcsd, print=print, nousest=nousest)\n    return r",
  "history_output" : "",
  "history_begin_time" : 1668624360696,
  "history_end_time" : 1668624364794,
  "history_notes" : null,
  "history_process" : "cydlb6",
  "host_id" : "100001",
  "indicator" : "Done"
},]
