[{
  "history_id" : "h1noacik1nu",
  "history_input" : "from azure.storage.blob import ContainerClient\nimport cv2\nfrom datetime import datetime, timedelta\nimport numpy as np\nimport os\nfrom pyhdf.SD import SD, SDC\nfrom pyproj import Proj,transform\nimport re\nfrom scipy.interpolate import interp2d\nimport wget\n\nclass ModisSource:\n    modis_account_name = 'modissa'\n    modis_container_name = 'modis-061'\n    modis_account_url = 'https://' + modis_account_name + '.blob.core.windows.net/'\n    modis_blob_root = modis_account_url + modis_container_name + '/'\n        \n#     temp_dir = os.environ['MODISPATH']\n    temp_dir = 'data/modis'\n    if not os.path.isdir(temp_dir):\n        import tempfile\n        temp_dir = os.path.join(tempfile.gettempdir(),'modis')\n        os.makedirs(temp_dir,exist_ok=True)\n    tempfiles = os.listdir(temp_dir)\n    \n    print(f\"data\\\\modis.py: Modis dir is {temp_dir} contain {len(tempfiles)} files\")\n\n    fname = 'sn_bound_10deg.txt'\n    fn = os.path.join(temp_dir, fname)\n    if not os.path.isfile(fn):\n        wget.download(modis_blob_root + fname, fn)\n    \n    # Load this file into a table, where each row is (v,h,lonmin,lonmax,latmin,latmax)\n    modis_tile_extents = np.genfromtxt(fn, skip_header = 7, skip_footer = 3)\n    modis_container_client = ContainerClient(account_url=modis_account_url, \n                                             container_name=modis_container_name,\n                                             credential=None)\n    \ndef lat_lon_to_modis_tiles(lat,lon):\n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    return ModisSource.modis_tile_extents[ok.nonzero()[0], 1::-1].astype(np.int64)\ndef lat_lon_to_modis_tile(lat,lon):\n    \"\"\"\n    Get the modis tile indices (h,v) for a given lat/lon    \n    https://www.earthdatascience.org/tutorials/convert-modis-tile-to-lat-lon/\n    \"\"\"    \n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    i = ok.nonzero()[0]\n    i = i[1] if len(i) >=3 else i[-1]\n    return int(ModisSource.modis_tile_extents[i, 1]),int(ModisSource.modis_tile_extents[i, 0])\n\ndef list_blobs_in_folder(container_name,folder_name):\n    generator = ModisSource.modis_container_client.list_blobs(name_starts_with=folder_name)\n    return [blob.name for blob in generator]\n            \ndef list_hdf_blobs_in_folder(container_name,folder_name):\n    files = list_blobs_in_folder(container_name,folder_name)\n    return [fn for fn in files if fn.endswith('.hdf')]\n\nul_regex = re.compile(r'''UpperLeftPointMtrs=\\(\n                          (?P<upper_left_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<upper_left_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\nlr_regex = re.compile(r'''LowerRightMtrs=\\(\n                          (?P<lower_right_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<lower_right_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\n\n# keys = ['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI']\n# keys = ['NDSI_Snow_Cover', 'NDSI']\nkeys = ['NDSI_Snow_Cover']\nqakey = 'NDSI_Snow_Cover_Basic_QA'\n\ndef calibrate(hdf, keys=None):\n    ga = hdf.attributes()['StructMetadata.0']\n    match = ul_regex.search(ga)\n    x0 = float(match.group('upper_left_x'))\n    y0 = float(match.group('upper_left_y'))\n    match = lr_regex.search(ga)\n    x1 = float(match.group('lower_right_x'))\n    y1 = float(match.group('lower_right_y'))\n    out = {}\n    for key in hdf.datasets():\n        if keys is not None:\n            if key not in keys and key != qakey:\n                continue\n        f = hdf.select(key)\n        data = f.get()\n        attr = f.attributes()    \n        # print(attr)\n        data_c = data.astype(np.float32)\n        if 'scale_factor' in attr:\n            data_c = data_c * float(attr['scale_factor'])            \n        if '_FillValue' in attr:\n            data_c[data==attr['_FillValue']] = np.nan\n        if 'valid_range' in attr:\n            valid_range = attr['valid_range']\n            data_c = np.minimum(np.maximum(data_c, valid_range[0]), valid_range[1])\n        out[key] = data_c\n    qa = out[qakey]==4\n    out['NDSI_Snow_Cover'][qa] = np.nan\n    if qakey not in keys:\n        out.pop(qakey)\n    return out,x0,x1,y0,y1\n    \ndef getmodis_hv(product, h, v, date, verbose=True):\n    # Files are stored according to:\n    # http://modissa.blob.core.windows.net/modis-006/[product]/[htile]/[vtile]/[year][day]/filename\n    # This is the MODIS surface reflectance product\n    folder = product + '/' + '{:0>2d}/{:0>2d}'.format(h,v) + '/' + date.strftime('%Y%j')\n    # Find all HDF files from this tile on this day    \n    # filename = folder+'/'+product+'.A'+date.strftime('%Y%j')+'.h{:0>2d}v{:0>2d}'.format(h,v)+'.006'+\n    filename = folder.replace('/','_')\n    filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    if len(filenames) == 0:\n        ModisSource.tempfiles = os.listdir(ModisSource.temp_dir)\n        filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    ex = False\n    if len(filenames) > 0:        \n        filename = os.path.join(ModisSource.temp_dir,filenames[0])\n        ex = os.path.isfile(filename)\n    if not ex:\n        filenames = list_hdf_blobs_in_folder(ModisSource.modis_container_name,folder)\n        if verbose:\n            print('Found {} matching file(s):'.format(len(filenames)))\n            for fn in filenames:\n                print(fn)    \n        if len(filenames) == 0:\n            return None\n        filename = os.path.join(ModisSource.temp_dir, filenames[0].replace('/','_'))\n        print(filename)\n        if not os.path.isfile(filename):\n            # Download to a temporary file\n            wget.download(ModisSource.modis_blob_root + filenames[0], filename)\n    return SD(filename, SDC.READ)\n\ndef getmodis_lat_lon(product, lat, lon, date, verbose=True):\n    h,v = lat_lon_to_modis_tile(lat,lon)\n    return getmodis_hv(product, h, v, date, verbose)\n\nrgauss = 2.0\ndef getaver (lon,lat,lons,lats,elev,ex,r):\n    ry = r/(1110./(lat.shape[0]-1))\n    mask = (2*int(rgauss*ry)+1, 2*int(rgauss*ry)+1)\n    av = np.nan_to_num(cv2.GaussianBlur(elev, mask, ry)/cv2.GaussianBlur(ex, mask, ry),-9999.)\n    f = interp2d(lon, lat, av, kind='linear')\n    ret = np.array([f(lons[k], lats[k])[0] for k in range(lons.shape[0])])\n    ret[ret<0.] = np.nan\n    return ret\n\nsinu = Proj('+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs')\n# wgs84 = Proj(\"+init=EPSG:4326\")\n# ih = np.array([[8,4],[8,5],[9,4],[9,5],[10,4]])\nih = np.array([[9,5],[8,4],[8,5],[9,4],[10,4]])\ndef getinterpolated(product, lat, lon, date, rads, verbose=False, keys=keys, new=True):    \n    out = {}\n    if keys is not None:\n        if new:\n            for r in rads:\n                out.update({key+str(r): np.full_like(lat, np.nan) for key in keys})\n        else:\n            out.update({key: np.full_like(lat, np.nan) for key in keys})\n    # x, y = transform(wgs84, sinu, lon, lat)\n    x, y = sinu(lon, lat)\n    ihs = [lat_lon_to_modis_tiles(latk,lonk) for lonk,latk in zip(lon,lat)]\n    ih = np.unique(np.concatenate (ihs,0), axis=0)\n    # badhv = np.array([[7,5],[8,4],[11,4]])    \n    for ifile in range(ih.shape[0]):\n        hdf = getmodis_hv(product, ih[ifile][0], ih[ifile][1], date, verbose=False)\n        if hdf is None:\n            continue\n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        sz = m[list(m.keys())[0]].shape\n        ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n        xm = np.linspace(x0,x1,sz[0])\n        ym = np.linspace(y0,y1,sz[1])\n        xs=x[ok]; ys=y[ok]\n        print(f\"ih={ih[ifile]} count={ok.sum()}\")\n        for key in m:\n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                if key+str(r) in out:\n                    v0 = out[key+str(r)][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                out[key+str(r)][ok] = v\n    bad = [key for key in out if np.isnan(out[key]).all()]\n    for key in bad:\n        out.pop(key)\n    if verbose:\n        print([date, {key: np.isfinite(out[key]).sum() for key in out}])\n    return out\n\n# hdf = getmodis_hv('MOD10A1', 8,4,datetime(2003,6,10))\n# m,x0,x1,y0,y1 = calibrate(hdf, keys=['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI'])\ndef getfields(product, date, h, v, out={}, verbose=False, keys=keys):\n    hdf = getmodis_hv(product, h, v, date, verbose=verbose)\n    if hdf is not None:        \n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        out['corners'] = x0,x1,y0,y1\n        for key in m:            \n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            if key in out:\n                out[key] += fld; out[key+'_c'] += ex\n            else:\n                out[key]  = fld; out[key+'_c']  = ex\n            print(f\"{product} {date} {h}_{v} {key} {fld.sum()/ex.sum():.4}\")\n    return out\n\ndef getmeanfields(reqdates, reqdays, loaddates, keys=keys, out = {}):\n    reqdays = [d.replace('-','_') for d in reqdays]    \n    for ifile in range(ih.shape[0]):\n        hvstr = f'f_{ih[ifile][0]}_{ih[ifile][1]}_'\n        for date in loaddates:\n            read = False\n            for date1,tday1 in zip (reqdates, reqdays):\n                if np.abs(((date-date1).days+180)%365-180)<=14:\n                    read = True\n                    break\n            if read:\n                ret = [getfields(product, date, ih[ifile][0], ih[ifile][1], keys=keys) \n                       for product in ['MOD10A1', 'MYD10A1'][:1+(date>=datetime(2002,7,4))]]\n                ret = {key: np.nanmean([r[key] for r in ret if len(r)>0],0) for key in keys+['corners']}\n                for date1,tday1 in zip (reqdates, reqdays):\n                    if np.abs(((date-date1).days+180)%365-180)<=14:\n                        for key in ret:\n                            if key != 'corners':\n                                name = hvstr+tday1+'M'+key\n                                if name in out:\n                                    out[name] = out[name]+ret[key]\n                                else:\n                                    out[name] = ret[key].copy()\n                                # if np.isnan(out[name]).any():\n                                #     print(f\"{name} bads={np.isnan(out[name]).sum()} goods={np.isfinite(out[name]).sum()}\")\n                                # else:\n                                if name[-2:] == '_c':\n                                    print(f\"{name[:-2]} {(out[name[:-2]]/out[name]).mean():.4}\")\n                            elif hvstr+key not in out:\n                                out[hvstr+key] = ret[key]\n    for key in out:\n        if key+'_c' in out:\n            out[key] = out[key]/out[key+'_c']\n    for key in [k for k in out.keys() if k[-2:]=='_c']:\n        out.pop(key)\n    return out\n\ndef interpfields(arx, df, reqdates, reqdays, rads, verbose=False, keys=keys):\n    x, y = sinu(df['longitude'].values, df['latitude'].values)\n    for key in arx:\n        if key[-7:] != 'corners':\n            hvstr = '_'.join(key.split('_')[:3])+'_'\n            x0,x1,y0,y1 = arx[hvstr+'corners']\n            sz = arx[key].shape\n            ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n            xm = np.linspace(x0,x1,sz[0])\n            ym = np.linspace(y0,y1,sz[1])\n            xs=x[ok]; ys=y[ok]\n            print(f\"{key} count={ok.sum()}\")\n            ex = np.isfinite(arx[key]).astype(np.float32)\n            fld = np.nan_to_num(arx[key],0.)\n            key1 = key[len(hvstr):]\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                name = key1[:10].replace('_','-')+key1[10:]+str(r)\n                if name in df:\n                    v0 = df[name][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                else:\n                    df[name] = np.full_like(x, np.nan)\n                df[name][ok] = v\n    return df\n\nif __name__ == '__main__':\n    # import geojson\n    # import pandas as pd\n    # from os import path\n    # workdir = 'evaluation'\n    # # workdir = 'development'\n    # with open(path.join(workdir,'grid_cells.geojson')) as f:\n    #     grid = geojson.load(f)\n    # grid = pd.DataFrame([{'cell_id':g['properties']['cell_id'], 'region':g['properties']['region'], \n    #                       'corners': np.array(g['geometry']['coordinates'])} for g in grid['features']]).set_index('cell_id')\n    # gll = np.vstack(grid['corners'].values)    \n    # grid['latitude'] = gll[:,:,1].mean(1)\n    # grid['longitude'] = gll[:,:,0].mean(1)\n    # stmeta = pd.read_csv(path.join(workdir,'ground_measures_metadata.csv')).set_index('station_id')\n    \n    import matplotlib.pyplot as plt\n    file = getmodis_lat_lon('MYD10A1', 41.881832, -87.623177, datetime(2010, 5, 15))\n    print(list(file.datasets().keys()))    \n    rgb,x0,x1,y0,y1 = calibrate(file)\n    for key in rgb:\n        fig = plt.figure(frameon=False); ax = plt.Axes(fig,[0., 0., 1., 1.])\n        ax.set_axis_off(); fig.add_axes(ax)\n        plt.imshow(rgb[key])\n        ax.set_title(key)",
  "history_output" : "data\\modis.py: Modis dir is /var/folders/gl/8p9421ps1pj_ggqtwxl41s900000gn/T/modis contain 0 files\nTraceback (most recent call last):\n  File \"data_modis.py\", line 12, in <module>\n    class ModisSource:\n  File \"data_modis.py\", line 31, in ModisSource\n    wget.download(modis_blob_root + fname, fn)\n  File \"/Users/uhhmed/env_snowcast/lib/python3.8/site-packages/wget.py\", line 526, in download\n    (tmpfile, headers) = ulib.urlretrieve(binurl, tmpfile, callback)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 247, in urlretrieve\n    with contextlib.closing(urlopen(url, data)) as fp:\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 222, in urlopen\n    return opener.open(url, data, timeout)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 531, in open\n    response = meth(req, response)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 640, in http_response\n    response = self.parent.error(\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 569, in error\n    return self._call_chain(*args)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 502, in _call_chain\n    result = func(*args)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 649, in http_error_default\n    raise HTTPError(req.full_url, code, msg, hdrs, fp)\nurllib.error.HTTPError: HTTP Error 409: Public access is not permitted on this storage account.\n",
  "history_begin_time" : 1668624385599,
  "history_end_time" : 1668624386938,
  "history_notes" : null,
  "history_process" : "mxd0ok",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "U39Kd6ou31KI",
  "history_input" : "from azure.storage.blob import ContainerClient\nimport cv2\nfrom datetime import datetime, timedelta\nimport numpy as np\nimport os\nfrom pyhdf.SD import SD, SDC\nfrom pyproj import Proj,transform\nimport re\nfrom scipy.interpolate import interp2d\nimport wget\n\nclass ModisSource:\n    modis_account_name = 'modissa'\n    modis_container_name = 'modis-061'\n    modis_account_url = 'https://' + modis_account_name + '.blob.core.windows.net/'\n    modis_blob_root = modis_account_url + modis_container_name + '/'\n        \n#     temp_dir = os.environ['MODISPATH']\n    temp_dir = 'data/modis'\n    if not os.path.isdir(temp_dir):\n        import tempfile\n        temp_dir = os.path.join(tempfile.gettempdir(),'modis')\n        os.makedirs(temp_dir,exist_ok=True)\n    tempfiles = os.listdir(temp_dir)\n    \n    print(f\"data\\\\modis.py: Modis dir is {temp_dir} contain {len(tempfiles)} files\")\n\n    fname = 'sn_bound_10deg.txt'\n    fn = os.path.join(temp_dir, fname)\n    if not os.path.isfile(fn):\n        wget.download(modis_blob_root + fname, fn)\n    \n    # Load this file into a table, where each row is (v,h,lonmin,lonmax,latmin,latmax)\n    modis_tile_extents = np.genfromtxt(fn, skip_header = 7, skip_footer = 3)\n    modis_container_client = ContainerClient(account_url=modis_account_url, \n                                             container_name=modis_container_name,\n                                             credential=None)\n    \ndef lat_lon_to_modis_tiles(lat,lon):\n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    return ModisSource.modis_tile_extents[ok.nonzero()[0], 1::-1].astype(np.int64)\ndef lat_lon_to_modis_tile(lat,lon):\n    \"\"\"\n    Get the modis tile indices (h,v) for a given lat/lon    \n    https://www.earthdatascience.org/tutorials/convert-modis-tile-to-lat-lon/\n    \"\"\"    \n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    i = ok.nonzero()[0]\n    i = i[1] if len(i) >=3 else i[-1]\n    return int(ModisSource.modis_tile_extents[i, 1]),int(ModisSource.modis_tile_extents[i, 0])\n\ndef list_blobs_in_folder(container_name,folder_name):\n    generator = ModisSource.modis_container_client.list_blobs(name_starts_with=folder_name)\n    return [blob.name for blob in generator]\n            \ndef list_hdf_blobs_in_folder(container_name,folder_name):\n    files = list_blobs_in_folder(container_name,folder_name)\n    return [fn for fn in files if fn.endswith('.hdf')]\n\nul_regex = re.compile(r'''UpperLeftPointMtrs=\\(\n                          (?P<upper_left_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<upper_left_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\nlr_regex = re.compile(r'''LowerRightMtrs=\\(\n                          (?P<lower_right_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<lower_right_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\n\n# keys = ['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI']\n# keys = ['NDSI_Snow_Cover', 'NDSI']\nkeys = ['NDSI_Snow_Cover']\nqakey = 'NDSI_Snow_Cover_Basic_QA'\n\ndef calibrate(hdf, keys=None):\n    ga = hdf.attributes()['StructMetadata.0']\n    match = ul_regex.search(ga)\n    x0 = float(match.group('upper_left_x'))\n    y0 = float(match.group('upper_left_y'))\n    match = lr_regex.search(ga)\n    x1 = float(match.group('lower_right_x'))\n    y1 = float(match.group('lower_right_y'))\n    out = {}\n    for key in hdf.datasets():\n        if keys is not None:\n            if key not in keys and key != qakey:\n                continue\n        f = hdf.select(key)\n        data = f.get()\n        attr = f.attributes()    \n        # print(attr)\n        data_c = data.astype(np.float32)\n        if 'scale_factor' in attr:\n            data_c = data_c * float(attr['scale_factor'])            \n        if '_FillValue' in attr:\n            data_c[data==attr['_FillValue']] = np.nan\n        if 'valid_range' in attr:\n            valid_range = attr['valid_range']\n            data_c = np.minimum(np.maximum(data_c, valid_range[0]), valid_range[1])\n        out[key] = data_c\n    qa = out[qakey]==4\n    out['NDSI_Snow_Cover'][qa] = np.nan\n    if qakey not in keys:\n        out.pop(qakey)\n    return out,x0,x1,y0,y1\n    \ndef getmodis_hv(product, h, v, date, verbose=True):\n    # Files are stored according to:\n    # http://modissa.blob.core.windows.net/modis-006/[product]/[htile]/[vtile]/[year][day]/filename\n    # This is the MODIS surface reflectance product\n    folder = product + '/' + '{:0>2d}/{:0>2d}'.format(h,v) + '/' + date.strftime('%Y%j')\n    # Find all HDF files from this tile on this day    \n    # filename = folder+'/'+product+'.A'+date.strftime('%Y%j')+'.h{:0>2d}v{:0>2d}'.format(h,v)+'.006'+\n    filename = folder.replace('/','_')\n    filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    if len(filenames) == 0:\n        ModisSource.tempfiles = os.listdir(ModisSource.temp_dir)\n        filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    ex = False\n    if len(filenames) > 0:        \n        filename = os.path.join(ModisSource.temp_dir,filenames[0])\n        ex = os.path.isfile(filename)\n    if not ex:\n        filenames = list_hdf_blobs_in_folder(ModisSource.modis_container_name,folder)\n        if verbose:\n            print('Found {} matching file(s):'.format(len(filenames)))\n            for fn in filenames:\n                print(fn)    \n        if len(filenames) == 0:\n            return None\n        filename = os.path.join(ModisSource.temp_dir, filenames[0].replace('/','_'))\n        print(filename)\n        if not os.path.isfile(filename):\n            # Download to a temporary file\n            wget.download(ModisSource.modis_blob_root + filenames[0], filename)\n    return SD(filename, SDC.READ)\n\ndef getmodis_lat_lon(product, lat, lon, date, verbose=True):\n    h,v = lat_lon_to_modis_tile(lat,lon)\n    return getmodis_hv(product, h, v, date, verbose)\n\nrgauss = 2.0\ndef getaver (lon,lat,lons,lats,elev,ex,r):\n    ry = r/(1110./(lat.shape[0]-1))\n    mask = (2*int(rgauss*ry)+1, 2*int(rgauss*ry)+1)\n    av = np.nan_to_num(cv2.GaussianBlur(elev, mask, ry)/cv2.GaussianBlur(ex, mask, ry),-9999.)\n    f = interp2d(lon, lat, av, kind='linear')\n    ret = np.array([f(lons[k], lats[k])[0] for k in range(lons.shape[0])])\n    ret[ret<0.] = np.nan\n    return ret\n\nsinu = Proj('+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs')\n# wgs84 = Proj(\"+init=EPSG:4326\")\n# ih = np.array([[8,4],[8,5],[9,4],[9,5],[10,4]])\nih = np.array([[9,5],[8,4],[8,5],[9,4],[10,4]])\ndef getinterpolated(product, lat, lon, date, rads, verbose=False, keys=keys, new=True):    \n    out = {}\n    if keys is not None:\n        if new:\n            for r in rads:\n                out.update({key+str(r): np.full_like(lat, np.nan) for key in keys})\n        else:\n            out.update({key: np.full_like(lat, np.nan) for key in keys})\n    # x, y = transform(wgs84, sinu, lon, lat)\n    x, y = sinu(lon, lat)\n    ihs = [lat_lon_to_modis_tiles(latk,lonk) for lonk,latk in zip(lon,lat)]\n    ih = np.unique(np.concatenate (ihs,0), axis=0)\n    # badhv = np.array([[7,5],[8,4],[11,4]])    \n    for ifile in range(ih.shape[0]):\n        hdf = getmodis_hv(product, ih[ifile][0], ih[ifile][1], date, verbose=False)\n        if hdf is None:\n            continue\n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        sz = m[list(m.keys())[0]].shape\n        ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n        xm = np.linspace(x0,x1,sz[0])\n        ym = np.linspace(y0,y1,sz[1])\n        xs=x[ok]; ys=y[ok]\n        print(f\"ih={ih[ifile]} count={ok.sum()}\")\n        for key in m:\n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                if key+str(r) in out:\n                    v0 = out[key+str(r)][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                out[key+str(r)][ok] = v\n    bad = [key for key in out if np.isnan(out[key]).all()]\n    for key in bad:\n        out.pop(key)\n    if verbose:\n        print([date, {key: np.isfinite(out[key]).sum() for key in out}])\n    return out\n\n# hdf = getmodis_hv('MOD10A1', 8,4,datetime(2003,6,10))\n# m,x0,x1,y0,y1 = calibrate(hdf, keys=['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI'])\ndef getfields(product, date, h, v, out={}, verbose=False, keys=keys):\n    hdf = getmodis_hv(product, h, v, date, verbose=verbose)\n    if hdf is not None:        \n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        out['corners'] = x0,x1,y0,y1\n        for key in m:            \n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            if key in out:\n                out[key] += fld; out[key+'_c'] += ex\n            else:\n                out[key]  = fld; out[key+'_c']  = ex\n            print(f\"{product} {date} {h}_{v} {key} {fld.sum()/ex.sum():.4}\")\n    return out\n\ndef getmeanfields(reqdates, reqdays, loaddates, keys=keys, out = {}):\n    reqdays = [d.replace('-','_') for d in reqdays]    \n    for ifile in range(ih.shape[0]):\n        hvstr = f'f_{ih[ifile][0]}_{ih[ifile][1]}_'\n        for date in loaddates:\n            read = False\n            for date1,tday1 in zip (reqdates, reqdays):\n                if np.abs(((date-date1).days+180)%365-180)<=14:\n                    read = True\n                    break\n            if read:\n                ret = [getfields(product, date, ih[ifile][0], ih[ifile][1], keys=keys) \n                       for product in ['MOD10A1', 'MYD10A1'][:1+(date>=datetime(2002,7,4))]]\n                ret = {key: np.nanmean([r[key] for r in ret if len(r)>0],0) for key in keys+['corners']}\n                for date1,tday1 in zip (reqdates, reqdays):\n                    if np.abs(((date-date1).days+180)%365-180)<=14:\n                        for key in ret:\n                            if key != 'corners':\n                                name = hvstr+tday1+'M'+key\n                                if name in out:\n                                    out[name] = out[name]+ret[key]\n                                else:\n                                    out[name] = ret[key].copy()\n                                # if np.isnan(out[name]).any():\n                                #     print(f\"{name} bads={np.isnan(out[name]).sum()} goods={np.isfinite(out[name]).sum()}\")\n                                # else:\n                                if name[-2:] == '_c':\n                                    print(f\"{name[:-2]} {(out[name[:-2]]/out[name]).mean():.4}\")\n                            elif hvstr+key not in out:\n                                out[hvstr+key] = ret[key]\n    for key in out:\n        if key+'_c' in out:\n            out[key] = out[key]/out[key+'_c']\n    for key in [k for k in out.keys() if k[-2:]=='_c']:\n        out.pop(key)\n    return out\n\ndef interpfields(arx, df, reqdates, reqdays, rads, verbose=False, keys=keys):\n    x, y = sinu(df['longitude'].values, df['latitude'].values)\n    for key in arx:\n        if key[-7:] != 'corners':\n            hvstr = '_'.join(key.split('_')[:3])+'_'\n            x0,x1,y0,y1 = arx[hvstr+'corners']\n            sz = arx[key].shape\n            ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n            xm = np.linspace(x0,x1,sz[0])\n            ym = np.linspace(y0,y1,sz[1])\n            xs=x[ok]; ys=y[ok]\n            print(f\"{key} count={ok.sum()}\")\n            ex = np.isfinite(arx[key]).astype(np.float32)\n            fld = np.nan_to_num(arx[key],0.)\n            key1 = key[len(hvstr):]\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                name = key1[:10].replace('_','-')+key1[10:]+str(r)\n                if name in df:\n                    v0 = df[name][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                else:\n                    df[name] = np.full_like(x, np.nan)\n                df[name][ok] = v\n    return df\n\nif __name__ == '__main__':\n    # import geojson\n    # import pandas as pd\n    # from os import path\n    # workdir = 'evaluation'\n    # # workdir = 'development'\n    # with open(path.join(workdir,'grid_cells.geojson')) as f:\n    #     grid = geojson.load(f)\n    # grid = pd.DataFrame([{'cell_id':g['properties']['cell_id'], 'region':g['properties']['region'], \n    #                       'corners': np.array(g['geometry']['coordinates'])} for g in grid['features']]).set_index('cell_id')\n    # gll = np.vstack(grid['corners'].values)    \n    # grid['latitude'] = gll[:,:,1].mean(1)\n    # grid['longitude'] = gll[:,:,0].mean(1)\n    # stmeta = pd.read_csv(path.join(workdir,'ground_measures_metadata.csv')).set_index('station_id')\n    \n    import matplotlib.pyplot as plt\n    file = getmodis_lat_lon('MYD10A1', 41.881832, -87.623177, datetime(2010, 5, 15))\n    print(list(file.datasets().keys()))    \n    rgb,x0,x1,y0,y1 = calibrate(file)\n    for key in rgb:\n        fig = plt.figure(frameon=False); ax = plt.Axes(fig,[0., 0., 1., 1.])\n        ax.set_axis_off(); fig.add_axes(ax)\n        plt.imshow(rgb[key])\n        ax.set_title(key)",
  "history_output" : "data\\modis.py: Modis dir is /var/folders/gl/8p9421ps1pj_ggqtwxl41s900000gn/T/modis contain 0 files\nTraceback (most recent call last):\n  File \"data_modis.py\", line 12, in <module>\n    class ModisSource:\n  File \"data_modis.py\", line 31, in ModisSource\n    wget.download(modis_blob_root + fname, fn)\n  File \"/Users/uhhmed/env_snowcast/lib/python3.8/site-packages/wget.py\", line 526, in download\n    (tmpfile, headers) = ulib.urlretrieve(binurl, tmpfile, callback)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 247, in urlretrieve\n    with contextlib.closing(urlopen(url, data)) as fp:\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 222, in urlopen\n    return opener.open(url, data, timeout)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 531, in open\n    response = meth(req, response)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 640, in http_response\n    response = self.parent.error(\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 569, in error\n    return self._call_chain(*args)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 502, in _call_chain\n    result = func(*args)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 649, in http_error_default\n    raise HTTPError(req.full_url, code, msg, hdrs, fp)\nurllib.error.HTTPError: HTTP Error 409: Public access is not permitted on this storage account.\n",
  "history_begin_time" : 1668624137821,
  "history_end_time" : 1668624141181,
  "history_notes" : null,
  "history_process" : "mxd0ok",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "OSmuAJUscBnd",
  "history_input" : "from azure.storage.blob import ContainerClient\nimport cv2\nfrom datetime import datetime, timedelta\nimport numpy as np\nimport os\nfrom pyhdf.SD import SD, SDC\nfrom pyproj import Proj,transform\nimport re\nfrom scipy.interpolate import interp2d\nimport wget\n\nclass ModisSource:\n    modis_account_name = 'modissa'\n    modis_container_name = 'modis-006'\n    modis_account_url = 'https://' + modis_account_name + '.blob.core.windows.net/'\n    modis_blob_root = modis_account_url + modis_container_name + '/'\n        \n#     temp_dir = os.environ['MODISPATH']\n    temp_dir = 'data/modis'\n    if not os.path.isdir(temp_dir):\n        import tempfile\n        temp_dir = os.path.join(tempfile.gettempdir(),'modis')\n        os.makedirs(temp_dir,exist_ok=True)\n    tempfiles = os.listdir(temp_dir)\n    \n    print(f\"data\\\\modis.py: Modis dir is {temp_dir} contain {len(tempfiles)} files\")\n\n    fname = 'sn_bound_10deg.txt'\n    fn = os.path.join(temp_dir, fname)\n    if not os.path.isfile(fn):\n        wget.download(modis_blob_root + fname, fn)\n    \n    # Load this file into a table, where each row is (v,h,lonmin,lonmax,latmin,latmax)\n    modis_tile_extents = np.genfromtxt(fn, skip_header = 7, skip_footer = 3)\n    modis_container_client = ContainerClient(account_url=modis_account_url, \n                                             container_name=modis_container_name,\n                                             credential=None)\n    \ndef lat_lon_to_modis_tiles(lat,lon):\n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    return ModisSource.modis_tile_extents[ok.nonzero()[0], 1::-1].astype(np.int64)\ndef lat_lon_to_modis_tile(lat,lon):\n    \"\"\"\n    Get the modis tile indices (h,v) for a given lat/lon    \n    https://www.earthdatascience.org/tutorials/convert-modis-tile-to-lat-lon/\n    \"\"\"    \n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    i = ok.nonzero()[0]\n    i = i[1] if len(i) >=3 else i[-1]\n    return int(ModisSource.modis_tile_extents[i, 1]),int(ModisSource.modis_tile_extents[i, 0])\n\ndef list_blobs_in_folder(container_name,folder_name):\n    generator = ModisSource.modis_container_client.list_blobs(name_starts_with=folder_name)\n    return [blob.name for blob in generator]\n            \ndef list_hdf_blobs_in_folder(container_name,folder_name):\n    files = list_blobs_in_folder(container_name,folder_name)\n    return [fn for fn in files if fn.endswith('.hdf')]\n\nul_regex = re.compile(r'''UpperLeftPointMtrs=\\(\n                          (?P<upper_left_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<upper_left_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\nlr_regex = re.compile(r'''LowerRightMtrs=\\(\n                          (?P<lower_right_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<lower_right_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\n\n# keys = ['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI']\n# keys = ['NDSI_Snow_Cover', 'NDSI']\nkeys = ['NDSI_Snow_Cover']\nqakey = 'NDSI_Snow_Cover_Basic_QA'\n\ndef calibrate(hdf, keys=None):\n    ga = hdf.attributes()['StructMetadata.0']\n    match = ul_regex.search(ga)\n    x0 = float(match.group('upper_left_x'))\n    y0 = float(match.group('upper_left_y'))\n    match = lr_regex.search(ga)\n    x1 = float(match.group('lower_right_x'))\n    y1 = float(match.group('lower_right_y'))\n    out = {}\n    for key in hdf.datasets():\n        if keys is not None:\n            if key not in keys and key != qakey:\n                continue\n        f = hdf.select(key)\n        data = f.get()\n        attr = f.attributes()    \n        # print(attr)\n        data_c = data.astype(np.float32)\n        if 'scale_factor' in attr:\n            data_c = data_c * float(attr['scale_factor'])            \n        if '_FillValue' in attr:\n            data_c[data==attr['_FillValue']] = np.nan\n        if 'valid_range' in attr:\n            valid_range = attr['valid_range']\n            data_c = np.minimum(np.maximum(data_c, valid_range[0]), valid_range[1])\n        out[key] = data_c\n    qa = out[qakey]==4\n    out['NDSI_Snow_Cover'][qa] = np.nan\n    if qakey not in keys:\n        out.pop(qakey)\n    return out,x0,x1,y0,y1\n    \ndef getmodis_hv(product, h, v, date, verbose=True):\n    # Files are stored according to:\n    # http://modissa.blob.core.windows.net/modis-006/[product]/[htile]/[vtile]/[year][day]/filename\n    # This is the MODIS surface reflectance product\n    folder = product + '/' + '{:0>2d}/{:0>2d}'.format(h,v) + '/' + date.strftime('%Y%j')\n    # Find all HDF files from this tile on this day    \n    # filename = folder+'/'+product+'.A'+date.strftime('%Y%j')+'.h{:0>2d}v{:0>2d}'.format(h,v)+'.006'+\n    filename = folder.replace('/','_')\n    filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    if len(filenames) == 0:\n        ModisSource.tempfiles = os.listdir(ModisSource.temp_dir)\n        filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    ex = False\n    if len(filenames) > 0:        \n        filename = os.path.join(ModisSource.temp_dir,filenames[0])\n        ex = os.path.isfile(filename)\n    if not ex:\n        filenames = list_hdf_blobs_in_folder(ModisSource.modis_container_name,folder)\n        if verbose:\n            print('Found {} matching file(s):'.format(len(filenames)))\n            for fn in filenames:\n                print(fn)    \n        if len(filenames) == 0:\n            return None\n        filename = os.path.join(ModisSource.temp_dir, filenames[0].replace('/','_'))\n        print(filename)\n        if not os.path.isfile(filename):\n            # Download to a temporary file\n            wget.download(ModisSource.modis_blob_root + filenames[0], filename)\n    return SD(filename, SDC.READ)\n\ndef getmodis_lat_lon(product, lat, lon, date, verbose=True):\n    h,v = lat_lon_to_modis_tile(lat,lon)\n    return getmodis_hv(product, h, v, date, verbose)\n\nrgauss = 2.0\ndef getaver (lon,lat,lons,lats,elev,ex,r):\n    ry = r/(1110./(lat.shape[0]-1))\n    mask = (2*int(rgauss*ry)+1, 2*int(rgauss*ry)+1)\n    av = np.nan_to_num(cv2.GaussianBlur(elev, mask, ry)/cv2.GaussianBlur(ex, mask, ry),-9999.)\n    f = interp2d(lon, lat, av, kind='linear')\n    ret = np.array([f(lons[k], lats[k])[0] for k in range(lons.shape[0])])\n    ret[ret<0.] = np.nan\n    return ret\n\nsinu = Proj('+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs')\n# wgs84 = Proj(\"+init=EPSG:4326\")\n# ih = np.array([[8,4],[8,5],[9,4],[9,5],[10,4]])\nih = np.array([[9,5],[8,4],[8,5],[9,4],[10,4]])\ndef getinterpolated(product, lat, lon, date, rads, verbose=False, keys=keys, new=True):    \n    out = {}\n    if keys is not None:\n        if new:\n            for r in rads:\n                out.update({key+str(r): np.full_like(lat, np.nan) for key in keys})\n        else:\n            out.update({key: np.full_like(lat, np.nan) for key in keys})\n    # x, y = transform(wgs84, sinu, lon, lat)\n    x, y = sinu(lon, lat)\n    ihs = [lat_lon_to_modis_tiles(latk,lonk) for lonk,latk in zip(lon,lat)]\n    ih = np.unique(np.concatenate (ihs,0), axis=0)\n    # badhv = np.array([[7,5],[8,4],[11,4]])    \n    for ifile in range(ih.shape[0]):\n        hdf = getmodis_hv(product, ih[ifile][0], ih[ifile][1], date, verbose=False)\n        if hdf is None:\n            continue\n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        sz = m[list(m.keys())[0]].shape\n        ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n        xm = np.linspace(x0,x1,sz[0])\n        ym = np.linspace(y0,y1,sz[1])\n        xs=x[ok]; ys=y[ok]\n        print(f\"ih={ih[ifile]} count={ok.sum()}\")\n        for key in m:\n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                if key+str(r) in out:\n                    v0 = out[key+str(r)][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                out[key+str(r)][ok] = v\n    bad = [key for key in out if np.isnan(out[key]).all()]\n    for key in bad:\n        out.pop(key)\n    if verbose:\n        print([date, {key: np.isfinite(out[key]).sum() for key in out}])\n    return out\n\n# hdf = getmodis_hv('MOD10A1', 8,4,datetime(2003,6,10))\n# m,x0,x1,y0,y1 = calibrate(hdf, keys=['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI'])\ndef getfields(product, date, h, v, out={}, verbose=False, keys=keys):\n    hdf = getmodis_hv(product, h, v, date, verbose=verbose)\n    if hdf is not None:        \n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        out['corners'] = x0,x1,y0,y1\n        for key in m:            \n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            if key in out:\n                out[key] += fld; out[key+'_c'] += ex\n            else:\n                out[key]  = fld; out[key+'_c']  = ex\n            print(f\"{product} {date} {h}_{v} {key} {fld.sum()/ex.sum():.4}\")\n    return out\n\ndef getmeanfields(reqdates, reqdays, loaddates, keys=keys, out = {}):\n    reqdays = [d.replace('-','_') for d in reqdays]    \n    for ifile in range(ih.shape[0]):\n        hvstr = f'f_{ih[ifile][0]}_{ih[ifile][1]}_'\n        for date in loaddates:\n            read = False\n            for date1,tday1 in zip (reqdates, reqdays):\n                if np.abs(((date-date1).days+180)%365-180)<=14:\n                    read = True\n                    break\n            if read:\n                ret = [getfields(product, date, ih[ifile][0], ih[ifile][1], keys=keys) \n                       for product in ['MOD10A1', 'MYD10A1'][:1+(date>=datetime(2002,7,4))]]\n                ret = {key: np.nanmean([r[key] for r in ret if len(r)>0],0) for key in keys+['corners']}\n                for date1,tday1 in zip (reqdates, reqdays):\n                    if np.abs(((date-date1).days+180)%365-180)<=14:\n                        for key in ret:\n                            if key != 'corners':\n                                name = hvstr+tday1+'M'+key\n                                if name in out:\n                                    out[name] = out[name]+ret[key]\n                                else:\n                                    out[name] = ret[key].copy()\n                                # if np.isnan(out[name]).any():\n                                #     print(f\"{name} bads={np.isnan(out[name]).sum()} goods={np.isfinite(out[name]).sum()}\")\n                                # else:\n                                if name[-2:] == '_c':\n                                    print(f\"{name[:-2]} {(out[name[:-2]]/out[name]).mean():.4}\")\n                            elif hvstr+key not in out:\n                                out[hvstr+key] = ret[key]\n    for key in out:\n        if key+'_c' in out:\n            out[key] = out[key]/out[key+'_c']\n    for key in [k for k in out.keys() if k[-2:]=='_c']:\n        out.pop(key)\n    return out\n\ndef interpfields(arx, df, reqdates, reqdays, rads, verbose=False, keys=keys):\n    x, y = sinu(df['longitude'].values, df['latitude'].values)\n    for key in arx:\n        if key[-7:] != 'corners':\n            hvstr = '_'.join(key.split('_')[:3])+'_'\n            x0,x1,y0,y1 = arx[hvstr+'corners']\n            sz = arx[key].shape\n            ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n            xm = np.linspace(x0,x1,sz[0])\n            ym = np.linspace(y0,y1,sz[1])\n            xs=x[ok]; ys=y[ok]\n            print(f\"{key} count={ok.sum()}\")\n            ex = np.isfinite(arx[key]).astype(np.float32)\n            fld = np.nan_to_num(arx[key],0.)\n            key1 = key[len(hvstr):]\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                name = key1[:10].replace('_','-')+key1[10:]+str(r)\n                if name in df:\n                    v0 = df[name][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                else:\n                    df[name] = np.full_like(x, np.nan)\n                df[name][ok] = v\n    return df\n\nif __name__ == '__main__':\n    # import geojson\n    # import pandas as pd\n    # from os import path\n    # workdir = 'evaluation'\n    # # workdir = 'development'\n    # with open(path.join(workdir,'grid_cells.geojson')) as f:\n    #     grid = geojson.load(f)\n    # grid = pd.DataFrame([{'cell_id':g['properties']['cell_id'], 'region':g['properties']['region'], \n    #                       'corners': np.array(g['geometry']['coordinates'])} for g in grid['features']]).set_index('cell_id')\n    # gll = np.vstack(grid['corners'].values)    \n    # grid['latitude'] = gll[:,:,1].mean(1)\n    # grid['longitude'] = gll[:,:,0].mean(1)\n    # stmeta = pd.read_csv(path.join(workdir,'ground_measures_metadata.csv')).set_index('station_id')\n    \n    import matplotlib.pyplot as plt\n    file = getmodis_lat_lon('MYD10A1', 41.881832, -87.623177, datetime(2010, 5, 15))\n    print(list(file.datasets().keys()))    \n    rgb,x0,x1,y0,y1 = calibrate(file)\n    for key in rgb:\n        fig = plt.figure(frameon=False); ax = plt.Axes(fig,[0., 0., 1., 1.])\n        ax.set_axis_off(); fig.add_axes(ax)\n        plt.imshow(rgb[key])\n        ax.set_title(key)",
  "history_output" : "data\\modis.py: Modis dir is /var/folders/gl/8p9421ps1pj_ggqtwxl41s900000gn/T/modis contain 0 files\nTraceback (most recent call last):\n  File \"data_modis.py\", line 12, in <module>\n    class ModisSource:\n  File \"data_modis.py\", line 31, in ModisSource\n    wget.download(modis_blob_root + fname, fn)\n  File \"/Users/uhhmed/env_snowcast/lib/python3.8/site-packages/wget.py\", line 526, in download\n    (tmpfile, headers) = ulib.urlretrieve(binurl, tmpfile, callback)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 247, in urlretrieve\n    with contextlib.closing(urlopen(url, data)) as fp:\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 222, in urlopen\n    return opener.open(url, data, timeout)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 531, in open\n    response = meth(req, response)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 640, in http_response\n    response = self.parent.error(\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 569, in error\n    return self._call_chain(*args)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 502, in _call_chain\n    result = func(*args)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 649, in http_error_default\n    raise HTTPError(req.full_url, code, msg, hdrs, fp)\nurllib.error.HTTPError: HTTP Error 409: Public access is not permitted on this storage account.\n",
  "history_begin_time" : 1668033050359,
  "history_end_time" : 1668033052788,
  "history_notes" : null,
  "history_process" : "mxd0ok",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "b5d1hSUJW4CG",
  "history_input" : "from azure.storage.blob import ContainerClient\nimport cv2\nfrom datetime import datetime, timedelta\nimport numpy as np\nimport os\nfrom pyhdf.SD import SD, SDC\nfrom pyproj import Proj,transform\nimport re\nfrom scipy.interpolate import interp2d\nimport wget\n\nclass ModisSource:\n    modis_account_name = 'modissa'\n    modis_container_name = 'modis-006'\n    modis_account_url = 'https://' + modis_account_name + '.blob.core.windows.net/'\n    modis_blob_root = modis_account_url + modis_container_name + '/'\n        \n#     temp_dir = os.environ['MODISPATH']\n    temp_dir = 'data/modis'\n    if not os.path.isdir(temp_dir):\n        import tempfile\n        temp_dir = os.path.join(tempfile.gettempdir(),'modis')\n        os.makedirs(temp_dir,exist_ok=True)\n    tempfiles = os.listdir(temp_dir)\n    \n    print(f\"data\\\\modis.py: Modis dir is {temp_dir} contain {len(tempfiles)} files\")\n\n    fname = 'sn_bound_10deg.txt'\n    fn = os.path.join(temp_dir, fname)\n    if not os.path.isfile(fn):\n        wget.download(modis_blob_root + fname, fn)\n    \n    # Load this file into a table, where each row is (v,h,lonmin,lonmax,latmin,latmax)\n    modis_tile_extents = np.genfromtxt(fn, skip_header = 7, skip_footer = 3)\n    modis_container_client = ContainerClient(account_url=modis_account_url, \n                                             container_name=modis_container_name,\n                                             credential=None)\n    \ndef lat_lon_to_modis_tiles(lat,lon):\n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    return ModisSource.modis_tile_extents[ok.nonzero()[0], 1::-1].astype(np.int64)\ndef lat_lon_to_modis_tile(lat,lon):\n    \"\"\"\n    Get the modis tile indices (h,v) for a given lat/lon    \n    https://www.earthdatascience.org/tutorials/convert-modis-tile-to-lat-lon/\n    \"\"\"    \n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    i = ok.nonzero()[0]\n    i = i[1] if len(i) >=3 else i[-1]\n    return int(ModisSource.modis_tile_extents[i, 1]),int(ModisSource.modis_tile_extents[i, 0])\n\ndef list_blobs_in_folder(container_name,folder_name):\n    generator = ModisSource.modis_container_client.list_blobs(name_starts_with=folder_name)\n    return [blob.name for blob in generator]\n            \ndef list_hdf_blobs_in_folder(container_name,folder_name):\n    files = list_blobs_in_folder(container_name,folder_name)\n    return [fn for fn in files if fn.endswith('.hdf')]\n\nul_regex = re.compile(r'''UpperLeftPointMtrs=\\(\n                          (?P<upper_left_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<upper_left_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\nlr_regex = re.compile(r'''LowerRightMtrs=\\(\n                          (?P<lower_right_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<lower_right_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\n\n# keys = ['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI']\n# keys = ['NDSI_Snow_Cover', 'NDSI']\nkeys = ['NDSI_Snow_Cover']\nqakey = 'NDSI_Snow_Cover_Basic_QA'\n\ndef calibrate(hdf, keys=None):\n    ga = hdf.attributes()['StructMetadata.0']\n    match = ul_regex.search(ga)\n    x0 = float(match.group('upper_left_x'))\n    y0 = float(match.group('upper_left_y'))\n    match = lr_regex.search(ga)\n    x1 = float(match.group('lower_right_x'))\n    y1 = float(match.group('lower_right_y'))\n    out = {}\n    for key in hdf.datasets():\n        if keys is not None:\n            if key not in keys and key != qakey:\n                continue\n        f = hdf.select(key)\n        data = f.get()\n        attr = f.attributes()    \n        # print(attr)\n        data_c = data.astype(np.float32)\n        if 'scale_factor' in attr:\n            data_c = data_c * float(attr['scale_factor'])            \n        if '_FillValue' in attr:\n            data_c[data==attr['_FillValue']] = np.nan\n        if 'valid_range' in attr:\n            valid_range = attr['valid_range']\n            data_c = np.minimum(np.maximum(data_c, valid_range[0]), valid_range[1])\n        out[key] = data_c\n    qa = out[qakey]==4\n    out['NDSI_Snow_Cover'][qa] = np.nan\n    if qakey not in keys:\n        out.pop(qakey)\n    return out,x0,x1,y0,y1\n    \ndef getmodis_hv(product, h, v, date, verbose=True):\n    # Files are stored according to:\n    # http://modissa.blob.core.windows.net/modis-006/[product]/[htile]/[vtile]/[year][day]/filename\n    # This is the MODIS surface reflectance product\n    folder = product + '/' + '{:0>2d}/{:0>2d}'.format(h,v) + '/' + date.strftime('%Y%j')\n    # Find all HDF files from this tile on this day    \n    # filename = folder+'/'+product+'.A'+date.strftime('%Y%j')+'.h{:0>2d}v{:0>2d}'.format(h,v)+'.006'+\n    filename = folder.replace('/','_')\n    filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    if len(filenames) == 0:\n        ModisSource.tempfiles = os.listdir(ModisSource.temp_dir)\n        filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    ex = False\n    if len(filenames) > 0:        \n        filename = os.path.join(ModisSource.temp_dir,filenames[0])\n        ex = os.path.isfile(filename)\n    if not ex:\n        filenames = list_hdf_blobs_in_folder(ModisSource.modis_container_name,folder)\n        if verbose:\n            print('Found {} matching file(s):'.format(len(filenames)))\n            for fn in filenames:\n                print(fn)    \n        if len(filenames) == 0:\n            return None\n        filename = os.path.join(ModisSource.temp_dir, filenames[0].replace('/','_'))\n        print(filename)\n        if not os.path.isfile(filename):\n            # Download to a temporary file\n            wget.download(ModisSource.modis_blob_root + filenames[0], filename)\n    return SD(filename, SDC.READ)\n\ndef getmodis_lat_lon(product, lat, lon, date, verbose=True):\n    h,v = lat_lon_to_modis_tile(lat,lon)\n    return getmodis_hv(product, h, v, date, verbose)\n\nrgauss = 2.0\ndef getaver (lon,lat,lons,lats,elev,ex,r):\n    ry = r/(1110./(lat.shape[0]-1))\n    mask = (2*int(rgauss*ry)+1, 2*int(rgauss*ry)+1)\n    av = np.nan_to_num(cv2.GaussianBlur(elev, mask, ry)/cv2.GaussianBlur(ex, mask, ry),-9999.)\n    f = interp2d(lon, lat, av, kind='linear')\n    ret = np.array([f(lons[k], lats[k])[0] for k in range(lons.shape[0])])\n    ret[ret<0.] = np.nan\n    return ret\n\nsinu = Proj('+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs')\n# wgs84 = Proj(\"+init=EPSG:4326\")\n# ih = np.array([[8,4],[8,5],[9,4],[9,5],[10,4]])\nih = np.array([[9,5],[8,4],[8,5],[9,4],[10,4]])\ndef getinterpolated(product, lat, lon, date, rads, verbose=False, keys=keys, new=True):    \n    out = {}\n    if keys is not None:\n        if new:\n            for r in rads:\n                out.update({key+str(r): np.full_like(lat, np.nan) for key in keys})\n        else:\n            out.update({key: np.full_like(lat, np.nan) for key in keys})\n    # x, y = transform(wgs84, sinu, lon, lat)\n    x, y = sinu(lon, lat)\n    ihs = [lat_lon_to_modis_tiles(latk,lonk) for lonk,latk in zip(lon,lat)]\n    ih = np.unique(np.concatenate (ihs,0), axis=0)\n    # badhv = np.array([[7,5],[8,4],[11,4]])    \n    for ifile in range(ih.shape[0]):\n        hdf = getmodis_hv(product, ih[ifile][0], ih[ifile][1], date, verbose=False)\n        if hdf is None:\n            continue\n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        sz = m[list(m.keys())[0]].shape\n        ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n        xm = np.linspace(x0,x1,sz[0])\n        ym = np.linspace(y0,y1,sz[1])\n        xs=x[ok]; ys=y[ok]\n        print(f\"ih={ih[ifile]} count={ok.sum()}\")\n        for key in m:\n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                if key+str(r) in out:\n                    v0 = out[key+str(r)][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                out[key+str(r)][ok] = v\n    bad = [key for key in out if np.isnan(out[key]).all()]\n    for key in bad:\n        out.pop(key)\n    if verbose:\n        print([date, {key: np.isfinite(out[key]).sum() for key in out}])\n    return out\n\n# hdf = getmodis_hv('MOD10A1', 8,4,datetime(2003,6,10))\n# m,x0,x1,y0,y1 = calibrate(hdf, keys=['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI'])\ndef getfields(product, date, h, v, out={}, verbose=False, keys=keys):\n    hdf = getmodis_hv(product, h, v, date, verbose=verbose)\n    if hdf is not None:        \n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        out['corners'] = x0,x1,y0,y1\n        for key in m:            \n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            if key in out:\n                out[key] += fld; out[key+'_c'] += ex\n            else:\n                out[key]  = fld; out[key+'_c']  = ex\n            print(f\"{product} {date} {h}_{v} {key} {fld.sum()/ex.sum():.4}\")\n    return out\n\ndef getmeanfields(reqdates, reqdays, loaddates, keys=keys, out = {}):\n    reqdays = [d.replace('-','_') for d in reqdays]    \n    for ifile in range(ih.shape[0]):\n        hvstr = f'f_{ih[ifile][0]}_{ih[ifile][1]}_'\n        for date in loaddates:\n            read = False\n            for date1,tday1 in zip (reqdates, reqdays):\n                if np.abs(((date-date1).days+180)%365-180)<=14:\n                    read = True\n                    break\n            if read:\n                ret = [getfields(product, date, ih[ifile][0], ih[ifile][1], keys=keys) \n                       for product in ['MOD10A1', 'MYD10A1'][:1+(date>=datetime(2002,7,4))]]\n                ret = {key: np.nanmean([r[key] for r in ret if len(r)>0],0) for key in keys+['corners']}\n                for date1,tday1 in zip (reqdates, reqdays):\n                    if np.abs(((date-date1).days+180)%365-180)<=14:\n                        for key in ret:\n                            if key != 'corners':\n                                name = hvstr+tday1+'M'+key\n                                if name in out:\n                                    out[name] = out[name]+ret[key]\n                                else:\n                                    out[name] = ret[key].copy()\n                                # if np.isnan(out[name]).any():\n                                #     print(f\"{name} bads={np.isnan(out[name]).sum()} goods={np.isfinite(out[name]).sum()}\")\n                                # else:\n                                if name[-2:] == '_c':\n                                    print(f\"{name[:-2]} {(out[name[:-2]]/out[name]).mean():.4}\")\n                            elif hvstr+key not in out:\n                                out[hvstr+key] = ret[key]\n    for key in out:\n        if key+'_c' in out:\n            out[key] = out[key]/out[key+'_c']\n    for key in [k for k in out.keys() if k[-2:]=='_c']:\n        out.pop(key)\n    return out\n\ndef interpfields(arx, df, reqdates, reqdays, rads, verbose=False, keys=keys):\n    x, y = sinu(df['longitude'].values, df['latitude'].values)\n    for key in arx:\n        if key[-7:] != 'corners':\n            hvstr = '_'.join(key.split('_')[:3])+'_'\n            x0,x1,y0,y1 = arx[hvstr+'corners']\n            sz = arx[key].shape\n            ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n            xm = np.linspace(x0,x1,sz[0])\n            ym = np.linspace(y0,y1,sz[1])\n            xs=x[ok]; ys=y[ok]\n            print(f\"{key} count={ok.sum()}\")\n            ex = np.isfinite(arx[key]).astype(np.float32)\n            fld = np.nan_to_num(arx[key],0.)\n            key1 = key[len(hvstr):]\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                name = key1[:10].replace('_','-')+key1[10:]+str(r)\n                if name in df:\n                    v0 = df[name][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                else:\n                    df[name] = np.full_like(x, np.nan)\n                df[name][ok] = v\n    return df\n\nif __name__ == '__main__':\n    # import geojson\n    # import pandas as pd\n    # from os import path\n    # workdir = 'evaluation'\n    # # workdir = 'development'\n    # with open(path.join(workdir,'grid_cells.geojson')) as f:\n    #     grid = geojson.load(f)\n    # grid = pd.DataFrame([{'cell_id':g['properties']['cell_id'], 'region':g['properties']['region'], \n    #                       'corners': np.array(g['geometry']['coordinates'])} for g in grid['features']]).set_index('cell_id')\n    # gll = np.vstack(grid['corners'].values)    \n    # grid['latitude'] = gll[:,:,1].mean(1)\n    # grid['longitude'] = gll[:,:,0].mean(1)\n    # stmeta = pd.read_csv(path.join(workdir,'ground_measures_metadata.csv')).set_index('station_id')\n    \n    import matplotlib.pyplot as plt\n    file = getmodis_lat_lon('MYD10A1', 41.881832, -87.623177, datetime(2010, 5, 15))\n    print(list(file.datasets().keys()))    \n    rgb,x0,x1,y0,y1 = calibrate(file)\n    for key in rgb:\n        fig = plt.figure(frameon=False); ax = plt.Axes(fig,[0., 0., 1., 1.])\n        ax.set_axis_off(); fig.add_axes(ax)\n        plt.imshow(rgb[key])\n        ax.set_title(key)",
  "history_output" : "data\\modis.py: Modis dir is /var/folders/gl/8p9421ps1pj_ggqtwxl41s900000gn/T/modis contain 0 files\nTraceback (most recent call last):\n  File \"data_modis.py\", line 12, in <module>\n    class ModisSource:\n  File \"data_modis.py\", line 31, in ModisSource\n    wget.download(modis_blob_root + fname, fn)\n  File \"/Users/uhhmed/env_snowcast/lib/python3.8/site-packages/wget.py\", line 526, in download\n    (tmpfile, headers) = ulib.urlretrieve(binurl, tmpfile, callback)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 247, in urlretrieve\n    with contextlib.closing(urlopen(url, data)) as fp:\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 222, in urlopen\n    return opener.open(url, data, timeout)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 531, in open\n    response = meth(req, response)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 640, in http_response\n    response = self.parent.error(\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 569, in error\n    return self._call_chain(*args)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 502, in _call_chain\n    result = func(*args)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 649, in http_error_default\n    raise HTTPError(req.full_url, code, msg, hdrs, fp)\nurllib.error.HTTPError: HTTP Error 409: Public access is not permitted on this storage account.\n",
  "history_begin_time" : 1668032935828,
  "history_end_time" : 1668032938376,
  "history_notes" : null,
  "history_process" : "mxd0ok",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "ed3YK5ZBVIac",
  "history_input" : "from azure.storage.blob import ContainerClient\nimport cv2\nfrom datetime import datetime, timedelta\nimport numpy as np\nimport os\nfrom pyhdf.SD import SD, SDC\nfrom pyproj import Proj,transform\nimport re\nfrom scipy.interpolate import interp2d\nimport wget\n\nclass ModisSource:\n    modis_account_name = 'modissa'\n    modis_container_name = 'modis-006'\n    modis_account_url = 'https://' + modis_account_name + '.blob.core.windows.net/'\n    modis_blob_root = modis_account_url + modis_container_name + '/'\n        \n#     temp_dir = os.environ['MODISPATH']\n    temp_dir = 'data/modis'\n    if not os.path.isdir(temp_dir):\n        import tempfile\n        temp_dir = os.path.join(tempfile.gettempdir(),'modis')\n        os.makedirs(temp_dir,exist_ok=True)\n    tempfiles = os.listdir(temp_dir)\n    \n    print(f\"data\\\\modis.py: Modis dir is {temp_dir} contain {len(tempfiles)} files\")\n\n    fname = 'sn_bound_10deg.txt'\n    fn = os.path.join(temp_dir, fname)\n    if not os.path.isfile(fn):\n        wget.download(modis_blob_root + fname, fn)\n    \n    # Load this file into a table, where each row is (v,h,lonmin,lonmax,latmin,latmax)\n    modis_tile_extents = np.genfromtxt(fn, skip_header = 7, skip_footer = 3)\n    modis_container_client = ContainerClient(account_url=modis_account_url, \n                                             container_name=modis_container_name,\n                                             credential=None)\n    \ndef lat_lon_to_modis_tiles(lat,lon):\n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    return ModisSource.modis_tile_extents[ok.nonzero()[0], 1::-1].astype(np.int64)\ndef lat_lon_to_modis_tile(lat,lon):\n    \"\"\"\n    Get the modis tile indices (h,v) for a given lat/lon    \n    https://www.earthdatascience.org/tutorials/convert-modis-tile-to-lat-lon/\n    \"\"\"    \n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    i = ok.nonzero()[0]\n    i = i[1] if len(i) >=3 else i[-1]\n    return int(ModisSource.modis_tile_extents[i, 1]),int(ModisSource.modis_tile_extents[i, 0])\n\ndef list_blobs_in_folder(container_name,folder_name):\n    generator = ModisSource.modis_container_client.list_blobs(name_starts_with=folder_name)\n    return [blob.name for blob in generator]\n            \ndef list_hdf_blobs_in_folder(container_name,folder_name):\n    files = list_blobs_in_folder(container_name,folder_name)\n    return [fn for fn in files if fn.endswith('.hdf')]\n\nul_regex = re.compile(r'''UpperLeftPointMtrs=\\(\n                          (?P<upper_left_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<upper_left_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\nlr_regex = re.compile(r'''LowerRightMtrs=\\(\n                          (?P<lower_right_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<lower_right_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\n\n# keys = ['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI']\n# keys = ['NDSI_Snow_Cover', 'NDSI']\nkeys = ['NDSI_Snow_Cover']\nqakey = 'NDSI_Snow_Cover_Basic_QA'\n\ndef calibrate(hdf, keys=None):\n    ga = hdf.attributes()['StructMetadata.0']\n    match = ul_regex.search(ga)\n    x0 = float(match.group('upper_left_x'))\n    y0 = float(match.group('upper_left_y'))\n    match = lr_regex.search(ga)\n    x1 = float(match.group('lower_right_x'))\n    y1 = float(match.group('lower_right_y'))\n    out = {}\n    for key in hdf.datasets():\n        if keys is not None:\n            if key not in keys and key != qakey:\n                continue\n        f = hdf.select(key)\n        data = f.get()\n        attr = f.attributes()    \n        # print(attr)\n        data_c = data.astype(np.float32)\n        if 'scale_factor' in attr:\n            data_c = data_c * float(attr['scale_factor'])            \n        if '_FillValue' in attr:\n            data_c[data==attr['_FillValue']] = np.nan\n        if 'valid_range' in attr:\n            valid_range = attr['valid_range']\n            data_c = np.minimum(np.maximum(data_c, valid_range[0]), valid_range[1])\n        out[key] = data_c\n    qa = out[qakey]==4\n    out['NDSI_Snow_Cover'][qa] = np.nan\n    if qakey not in keys:\n        out.pop(qakey)\n    return out,x0,x1,y0,y1\n    \ndef getmodis_hv(product, h, v, date, verbose=True):\n    # Files are stored according to:\n    # http://modissa.blob.core.windows.net/modis-006/[product]/[htile]/[vtile]/[year][day]/filename\n    # This is the MODIS surface reflectance product\n    folder = product + '/' + '{:0>2d}/{:0>2d}'.format(h,v) + '/' + date.strftime('%Y%j')\n    # Find all HDF files from this tile on this day    \n    # filename = folder+'/'+product+'.A'+date.strftime('%Y%j')+'.h{:0>2d}v{:0>2d}'.format(h,v)+'.006'+\n    filename = folder.replace('/','_')\n    filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    if len(filenames) == 0:\n        ModisSource.tempfiles = os.listdir(ModisSource.temp_dir)\n        filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    ex = False\n    if len(filenames) > 0:        \n        filename = os.path.join(ModisSource.temp_dir,filenames[0])\n        ex = os.path.isfile(filename)\n    if not ex:\n        filenames = list_hdf_blobs_in_folder(ModisSource.modis_container_name,folder)\n        if verbose:\n            print('Found {} matching file(s):'.format(len(filenames)))\n            for fn in filenames:\n                print(fn)    \n        if len(filenames) == 0:\n            return None\n        filename = os.path.join(ModisSource.temp_dir, filenames[0].replace('/','_'))\n        print(filename)\n        if not os.path.isfile(filename):\n            # Download to a temporary file\n            wget.download(ModisSource.modis_blob_root + filenames[0], filename)\n    return SD(filename, SDC.READ)\n\ndef getmodis_lat_lon(product, lat, lon, date, verbose=True):\n    h,v = lat_lon_to_modis_tile(lat,lon)\n    return getmodis_hv(product, h, v, date, verbose)\n\nrgauss = 2.0\ndef getaver (lon,lat,lons,lats,elev,ex,r):\n    ry = r/(1110./(lat.shape[0]-1))\n    mask = (2*int(rgauss*ry)+1, 2*int(rgauss*ry)+1)\n    av = np.nan_to_num(cv2.GaussianBlur(elev, mask, ry)/cv2.GaussianBlur(ex, mask, ry),-9999.)\n    f = interp2d(lon, lat, av, kind='linear')\n    ret = np.array([f(lons[k], lats[k])[0] for k in range(lons.shape[0])])\n    ret[ret<0.] = np.nan\n    return ret\n\nsinu = Proj('+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs')\n# wgs84 = Proj(\"+init=EPSG:4326\")\n# ih = np.array([[8,4],[8,5],[9,4],[9,5],[10,4]])\nih = np.array([[9,5],[8,4],[8,5],[9,4],[10,4]])\ndef getinterpolated(product, lat, lon, date, rads, verbose=False, keys=keys, new=True):    \n    out = {}\n    if keys is not None:\n        if new:\n            for r in rads:\n                out.update({key+str(r): np.full_like(lat, np.nan) for key in keys})\n        else:\n            out.update({key: np.full_like(lat, np.nan) for key in keys})\n    # x, y = transform(wgs84, sinu, lon, lat)\n    x, y = sinu(lon, lat)\n    ihs = [lat_lon_to_modis_tiles(latk,lonk) for lonk,latk in zip(lon,lat)]\n    ih = np.unique(np.concatenate (ihs,0), axis=0)\n    # badhv = np.array([[7,5],[8,4],[11,4]])    \n    for ifile in range(ih.shape[0]):\n        hdf = getmodis_hv(product, ih[ifile][0], ih[ifile][1], date, verbose=False)\n        if hdf is None:\n            continue\n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        sz = m[list(m.keys())[0]].shape\n        ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n        xm = np.linspace(x0,x1,sz[0])\n        ym = np.linspace(y0,y1,sz[1])\n        xs=x[ok]; ys=y[ok]\n        print(f\"ih={ih[ifile]} count={ok.sum()}\")\n        for key in m:\n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                if key+str(r) in out:\n                    v0 = out[key+str(r)][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                out[key+str(r)][ok] = v\n    bad = [key for key in out if np.isnan(out[key]).all()]\n    for key in bad:\n        out.pop(key)\n    if verbose:\n        print([date, {key: np.isfinite(out[key]).sum() for key in out}])\n    return out\n\n# hdf = getmodis_hv('MOD10A1', 8,4,datetime(2003,6,10))\n# m,x0,x1,y0,y1 = calibrate(hdf, keys=['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI'])\ndef getfields(product, date, h, v, out={}, verbose=False, keys=keys):\n    hdf = getmodis_hv(product, h, v, date, verbose=verbose)\n    if hdf is not None:        \n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        out['corners'] = x0,x1,y0,y1\n        for key in m:            \n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            if key in out:\n                out[key] += fld; out[key+'_c'] += ex\n            else:\n                out[key]  = fld; out[key+'_c']  = ex\n            print(f\"{product} {date} {h}_{v} {key} {fld.sum()/ex.sum():.4}\")\n    return out\n\ndef getmeanfields(reqdates, reqdays, loaddates, keys=keys, out = {}):\n    reqdays = [d.replace('-','_') for d in reqdays]    \n    for ifile in range(ih.shape[0]):\n        hvstr = f'f_{ih[ifile][0]}_{ih[ifile][1]}_'\n        for date in loaddates:\n            read = False\n            for date1,tday1 in zip (reqdates, reqdays):\n                if np.abs(((date-date1).days+180)%365-180)<=14:\n                    read = True\n                    break\n            if read:\n                ret = [getfields(product, date, ih[ifile][0], ih[ifile][1], keys=keys) \n                       for product in ['MOD10A1', 'MYD10A1'][:1+(date>=datetime(2002,7,4))]]\n                ret = {key: np.nanmean([r[key] for r in ret if len(r)>0],0) for key in keys+['corners']}\n                for date1,tday1 in zip (reqdates, reqdays):\n                    if np.abs(((date-date1).days+180)%365-180)<=14:\n                        for key in ret:\n                            if key != 'corners':\n                                name = hvstr+tday1+'M'+key\n                                if name in out:\n                                    out[name] = out[name]+ret[key]\n                                else:\n                                    out[name] = ret[key].copy()\n                                # if np.isnan(out[name]).any():\n                                #     print(f\"{name} bads={np.isnan(out[name]).sum()} goods={np.isfinite(out[name]).sum()}\")\n                                # else:\n                                if name[-2:] == '_c':\n                                    print(f\"{name[:-2]} {(out[name[:-2]]/out[name]).mean():.4}\")\n                            elif hvstr+key not in out:\n                                out[hvstr+key] = ret[key]\n    for key in out:\n        if key+'_c' in out:\n            out[key] = out[key]/out[key+'_c']\n    for key in [k for k in out.keys() if k[-2:]=='_c']:\n        out.pop(key)\n    return out\n\ndef interpfields(arx, df, reqdates, reqdays, rads, verbose=False, keys=keys):\n    x, y = sinu(df['longitude'].values, df['latitude'].values)\n    for key in arx:\n        if key[-7:] != 'corners':\n            hvstr = '_'.join(key.split('_')[:3])+'_'\n            x0,x1,y0,y1 = arx[hvstr+'corners']\n            sz = arx[key].shape\n            ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n            xm = np.linspace(x0,x1,sz[0])\n            ym = np.linspace(y0,y1,sz[1])\n            xs=x[ok]; ys=y[ok]\n            print(f\"{key} count={ok.sum()}\")\n            ex = np.isfinite(arx[key]).astype(np.float32)\n            fld = np.nan_to_num(arx[key],0.)\n            key1 = key[len(hvstr):]\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                name = key1[:10].replace('_','-')+key1[10:]+str(r)\n                if name in df:\n                    v0 = df[name][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                else:\n                    df[name] = np.full_like(x, np.nan)\n                df[name][ok] = v\n    return df\n\nif __name__ == '__main__':\n    # import geojson\n    # import pandas as pd\n    # from os import path\n    # workdir = 'evaluation'\n    # # workdir = 'development'\n    # with open(path.join(workdir,'grid_cells.geojson')) as f:\n    #     grid = geojson.load(f)\n    # grid = pd.DataFrame([{'cell_id':g['properties']['cell_id'], 'region':g['properties']['region'], \n    #                       'corners': np.array(g['geometry']['coordinates'])} for g in grid['features']]).set_index('cell_id')\n    # gll = np.vstack(grid['corners'].values)    \n    # grid['latitude'] = gll[:,:,1].mean(1)\n    # grid['longitude'] = gll[:,:,0].mean(1)\n    # stmeta = pd.read_csv(path.join(workdir,'ground_measures_metadata.csv')).set_index('station_id')\n    \n    import matplotlib.pyplot as plt\n    file = getmodis_lat_lon('MYD10A1', 41.881832, -87.623177, datetime(2010, 5, 15))\n    print(list(file.datasets().keys()))    \n    rgb,x0,x1,y0,y1 = calibrate(file)\n    for key in rgb:\n        fig = plt.figure(frameon=False); ax = plt.Axes(fig,[0., 0., 1., 1.])\n        ax.set_axis_off(); fig.add_axes(ax)\n        plt.imshow(rgb[key])\n        ax.set_title(key)",
  "history_output" : "data\\modis.py: Modis dir is /var/folders/gl/8p9421ps1pj_ggqtwxl41s900000gn/T/modis contain 0 files\nTraceback (most recent call last):\n  File \"data_modis.py\", line 12, in <module>\n    class ModisSource:\n  File \"data_modis.py\", line 31, in ModisSource\n    wget.download(modis_blob_root + fname, fn)\n  File \"/Users/uhhmed/env_snowcast/lib/python3.8/site-packages/wget.py\", line 526, in download\n    (tmpfile, headers) = ulib.urlretrieve(binurl, tmpfile, callback)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 247, in urlretrieve\n    with contextlib.closing(urlopen(url, data)) as fp:\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 222, in urlopen\n    return opener.open(url, data, timeout)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 531, in open\n    response = meth(req, response)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 640, in http_response\n    response = self.parent.error(\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 569, in error\n    return self._call_chain(*args)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 502, in _call_chain\n    result = func(*args)\n  File \"/opt/anaconda3/lib/python3.8/urllib/request.py\", line 649, in http_error_default\n    raise HTTPError(req.full_url, code, msg, hdrs, fp)\nurllib.error.HTTPError: HTTP Error 409: Public access is not permitted on this storage account.\n",
  "history_begin_time" : 1667950945586,
  "history_end_time" : 1667950947072,
  "history_notes" : null,
  "history_process" : "mxd0ok",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "NZ8lWlp1RdAH",
  "history_input" : "from azure.storage.blob import ContainerClient\nimport cv2\nfrom datetime import datetime, timedelta\nimport numpy as np\nimport os\nfrom pyhdf.SD import SD, SDC\nfrom pyproj import Proj,transform\nimport re\nfrom scipy.interpolate import interp2d\nimport wget\n\nclass ModisSource:\n    modis_account_name = 'modissa'\n    modis_container_name = 'modis-006'\n    modis_account_url = 'https://' + modis_account_name + '.blob.core.windows.net/'\n    modis_blob_root = modis_account_url + modis_container_name + '/'\n        \n    temp_dir = os.environ['MODISPATH']\n    if not os.path.isdir(temp_dir):\n        import tempfile\n        temp_dir = os.path.join(tempfile.gettempdir(),'modis')\n        os.makedirs(temp_dir,exist_ok=True)\n    tempfiles = os.listdir(temp_dir)\n    \n    print(f\"data\\\\modis.py: Modis dir is {temp_dir} contain {len(tempfiles)} files\")\n\n    fname = 'sn_bound_10deg.txt'\n    fn = os.path.join(temp_dir, fname)\n    if not os.path.isfile(fn):\n        wget.download(modis_blob_root + fname, fn)\n    \n    # Load this file into a table, where each row is (v,h,lonmin,lonmax,latmin,latmax)\n    modis_tile_extents = np.genfromtxt(fn, skip_header = 7, skip_footer = 3)\n    modis_container_client = ContainerClient(account_url=modis_account_url, \n                                             container_name=modis_container_name,\n                                             credential=None)\n    \ndef lat_lon_to_modis_tiles(lat,lon):\n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    return ModisSource.modis_tile_extents[ok.nonzero()[0], 1::-1].astype(np.int64)\ndef lat_lon_to_modis_tile(lat,lon):\n    \"\"\"\n    Get the modis tile indices (h,v) for a given lat/lon    \n    https://www.earthdatascience.org/tutorials/convert-modis-tile-to-lat-lon/\n    \"\"\"    \n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    i = ok.nonzero()[0]\n    i = i[1] if len(i) >=3 else i[-1]\n    return int(ModisSource.modis_tile_extents[i, 1]),int(ModisSource.modis_tile_extents[i, 0])\n\ndef list_blobs_in_folder(container_name,folder_name):\n    generator = ModisSource.modis_container_client.list_blobs(name_starts_with=folder_name)\n    return [blob.name for blob in generator]\n            \ndef list_hdf_blobs_in_folder(container_name,folder_name):\n    files = list_blobs_in_folder(container_name,folder_name)\n    return [fn for fn in files if fn.endswith('.hdf')]\n\nul_regex = re.compile(r'''UpperLeftPointMtrs=\\(\n                          (?P<upper_left_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<upper_left_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\nlr_regex = re.compile(r'''LowerRightMtrs=\\(\n                          (?P<lower_right_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<lower_right_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\n\n# keys = ['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI']\n# keys = ['NDSI_Snow_Cover', 'NDSI']\nkeys = ['NDSI_Snow_Cover']\nqakey = 'NDSI_Snow_Cover_Basic_QA'\n\ndef calibrate(hdf, keys=None):\n    ga = hdf.attributes()['StructMetadata.0']\n    match = ul_regex.search(ga)\n    x0 = float(match.group('upper_left_x'))\n    y0 = float(match.group('upper_left_y'))\n    match = lr_regex.search(ga)\n    x1 = float(match.group('lower_right_x'))\n    y1 = float(match.group('lower_right_y'))\n    out = {}\n    for key in hdf.datasets():\n        if keys is not None:\n            if key not in keys and key != qakey:\n                continue\n        f = hdf.select(key)\n        data = f.get()\n        attr = f.attributes()    \n        # print(attr)\n        data_c = data.astype(np.float32)\n        if 'scale_factor' in attr:\n            data_c = data_c * float(attr['scale_factor'])            \n        if '_FillValue' in attr:\n            data_c[data==attr['_FillValue']] = np.nan\n        if 'valid_range' in attr:\n            valid_range = attr['valid_range']\n            data_c = np.minimum(np.maximum(data_c, valid_range[0]), valid_range[1])\n        out[key] = data_c\n    qa = out[qakey]==4\n    out['NDSI_Snow_Cover'][qa] = np.nan\n    if qakey not in keys:\n        out.pop(qakey)\n    return out,x0,x1,y0,y1\n    \ndef getmodis_hv(product, h, v, date, verbose=True):\n    # Files are stored according to:\n    # http://modissa.blob.core.windows.net/modis-006/[product]/[htile]/[vtile]/[year][day]/filename\n    # This is the MODIS surface reflectance product\n    folder = product + '/' + '{:0>2d}/{:0>2d}'.format(h,v) + '/' + date.strftime('%Y%j')\n    # Find all HDF files from this tile on this day    \n    # filename = folder+'/'+product+'.A'+date.strftime('%Y%j')+'.h{:0>2d}v{:0>2d}'.format(h,v)+'.006'+\n    filename = folder.replace('/','_')\n    filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    if len(filenames) == 0:\n        ModisSource.tempfiles = os.listdir(ModisSource.temp_dir)\n        filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    ex = False\n    if len(filenames) > 0:        \n        filename = os.path.join(ModisSource.temp_dir,filenames[0])\n        ex = os.path.isfile(filename)\n    if not ex:\n        filenames = list_hdf_blobs_in_folder(ModisSource.modis_container_name,folder)\n        if verbose:\n            print('Found {} matching file(s):'.format(len(filenames)))\n            for fn in filenames:\n                print(fn)    \n        if len(filenames) == 0:\n            return None\n        filename = os.path.join(ModisSource.temp_dir, filenames[0].replace('/','_'))\n        print(filename)\n        if not os.path.isfile(filename):\n            # Download to a temporary file\n            wget.download(ModisSource.modis_blob_root + filenames[0], filename)\n    return SD(filename, SDC.READ)\n\ndef getmodis_lat_lon(product, lat, lon, date, verbose=True):\n    h,v = lat_lon_to_modis_tile(lat,lon)\n    return getmodis_hv(product, h, v, date, verbose)\n\nrgauss = 2.0\ndef getaver (lon,lat,lons,lats,elev,ex,r):\n    ry = r/(1110./(lat.shape[0]-1))\n    mask = (2*int(rgauss*ry)+1, 2*int(rgauss*ry)+1)\n    av = np.nan_to_num(cv2.GaussianBlur(elev, mask, ry)/cv2.GaussianBlur(ex, mask, ry),-9999.)\n    f = interp2d(lon, lat, av, kind='linear')\n    ret = np.array([f(lons[k], lats[k])[0] for k in range(lons.shape[0])])\n    ret[ret<0.] = np.nan\n    return ret\n\nsinu = Proj('+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs')\n# wgs84 = Proj(\"+init=EPSG:4326\")\n# ih = np.array([[8,4],[8,5],[9,4],[9,5],[10,4]])\nih = np.array([[9,5],[8,4],[8,5],[9,4],[10,4]])\ndef getinterpolated(product, lat, lon, date, rads, verbose=False, keys=keys, new=True):    \n    out = {}\n    if keys is not None:\n        if new:\n            for r in rads:\n                out.update({key+str(r): np.full_like(lat, np.nan) for key in keys})\n        else:\n            out.update({key: np.full_like(lat, np.nan) for key in keys})\n    # x, y = transform(wgs84, sinu, lon, lat)\n    x, y = sinu(lon, lat)\n    ihs = [lat_lon_to_modis_tiles(latk,lonk) for lonk,latk in zip(lon,lat)]\n    ih = np.unique(np.concatenate (ihs,0), axis=0)\n    # badhv = np.array([[7,5],[8,4],[11,4]])    \n    for ifile in range(ih.shape[0]):\n        hdf = getmodis_hv(product, ih[ifile][0], ih[ifile][1], date, verbose=False)\n        if hdf is None:\n            continue\n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        sz = m[list(m.keys())[0]].shape\n        ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n        xm = np.linspace(x0,x1,sz[0])\n        ym = np.linspace(y0,y1,sz[1])\n        xs=x[ok]; ys=y[ok]\n        print(f\"ih={ih[ifile]} count={ok.sum()}\")\n        for key in m:\n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                if key+str(r) in out:\n                    v0 = out[key+str(r)][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                out[key+str(r)][ok] = v\n    bad = [key for key in out if np.isnan(out[key]).all()]\n    for key in bad:\n        out.pop(key)\n    if verbose:\n        print([date, {key: np.isfinite(out[key]).sum() for key in out}])\n    return out\n\n# hdf = getmodis_hv('MOD10A1', 8,4,datetime(2003,6,10))\n# m,x0,x1,y0,y1 = calibrate(hdf, keys=['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI'])\ndef getfields(product, date, h, v, out={}, verbose=False, keys=keys):\n    hdf = getmodis_hv(product, h, v, date, verbose=verbose)\n    if hdf is not None:        \n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        out['corners'] = x0,x1,y0,y1\n        for key in m:            \n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            if key in out:\n                out[key] += fld; out[key+'_c'] += ex\n            else:\n                out[key]  = fld; out[key+'_c']  = ex\n            print(f\"{product} {date} {h}_{v} {key} {fld.sum()/ex.sum():.4}\")\n    return out\n\ndef getmeanfields(reqdates, reqdays, loaddates, keys=keys, out = {}):\n    reqdays = [d.replace('-','_') for d in reqdays]    \n    for ifile in range(ih.shape[0]):\n        hvstr = f'f_{ih[ifile][0]}_{ih[ifile][1]}_'\n        for date in loaddates:\n            read = False\n            for date1,tday1 in zip (reqdates, reqdays):\n                if np.abs(((date-date1).days+180)%365-180)<=14:\n                    read = True\n                    break\n            if read:\n                ret = [getfields(product, date, ih[ifile][0], ih[ifile][1], keys=keys) \n                       for product in ['MOD10A1', 'MYD10A1'][:1+(date>=datetime(2002,7,4))]]\n                ret = {key: np.nanmean([r[key] for r in ret if len(r)>0],0) for key in keys+['corners']}\n                for date1,tday1 in zip (reqdates, reqdays):\n                    if np.abs(((date-date1).days+180)%365-180)<=14:\n                        for key in ret:\n                            if key != 'corners':\n                                name = hvstr+tday1+'M'+key\n                                if name in out:\n                                    out[name] = out[name]+ret[key]\n                                else:\n                                    out[name] = ret[key].copy()\n                                # if np.isnan(out[name]).any():\n                                #     print(f\"{name} bads={np.isnan(out[name]).sum()} goods={np.isfinite(out[name]).sum()}\")\n                                # else:\n                                if name[-2:] == '_c':\n                                    print(f\"{name[:-2]} {(out[name[:-2]]/out[name]).mean():.4}\")\n                            elif hvstr+key not in out:\n                                out[hvstr+key] = ret[key]\n    for key in out:\n        if key+'_c' in out:\n            out[key] = out[key]/out[key+'_c']\n    for key in [k for k in out.keys() if k[-2:]=='_c']:\n        out.pop(key)\n    return out\n\ndef interpfields(arx, df, reqdates, reqdays, rads, verbose=False, keys=keys):\n    x, y = sinu(df['longitude'].values, df['latitude'].values)\n    for key in arx:\n        if key[-7:] != 'corners':\n            hvstr = '_'.join(key.split('_')[:3])+'_'\n            x0,x1,y0,y1 = arx[hvstr+'corners']\n            sz = arx[key].shape\n            ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n            xm = np.linspace(x0,x1,sz[0])\n            ym = np.linspace(y0,y1,sz[1])\n            xs=x[ok]; ys=y[ok]\n            print(f\"{key} count={ok.sum()}\")\n            ex = np.isfinite(arx[key]).astype(np.float32)\n            fld = np.nan_to_num(arx[key],0.)\n            key1 = key[len(hvstr):]\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                name = key1[:10].replace('_','-')+key1[10:]+str(r)\n                if name in df:\n                    v0 = df[name][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                else:\n                    df[name] = np.full_like(x, np.nan)\n                df[name][ok] = v\n    return df\n\nif __name__ == '__main__':\n    # import geojson\n    # import pandas as pd\n    # from os import path\n    # workdir = 'evaluation'\n    # # workdir = 'development'\n    # with open(path.join(workdir,'grid_cells.geojson')) as f:\n    #     grid = geojson.load(f)\n    # grid = pd.DataFrame([{'cell_id':g['properties']['cell_id'], 'region':g['properties']['region'], \n    #                       'corners': np.array(g['geometry']['coordinates'])} for g in grid['features']]).set_index('cell_id')\n    # gll = np.vstack(grid['corners'].values)    \n    # grid['latitude'] = gll[:,:,1].mean(1)\n    # grid['longitude'] = gll[:,:,0].mean(1)\n    # stmeta = pd.read_csv(path.join(workdir,'ground_measures_metadata.csv')).set_index('station_id')\n    \n    import matplotlib.pyplot as plt\n    file = getmodis_lat_lon('MYD10A1', 41.881832, -87.623177, datetime(2010, 5, 15))\n    print(list(file.datasets().keys()))    \n    rgb,x0,x1,y0,y1 = calibrate(file)\n    for key in rgb:\n        fig = plt.figure(frameon=False); ax = plt.Axes(fig,[0., 0., 1., 1.])\n        ax.set_axis_off(); fig.add_axes(ax)\n        plt.imshow(rgb[key])\n        ax.set_title(key)",
  "history_output" : "Traceback (most recent call last):\n  File \"data_modis.py\", line 12, in <module>\n    class ModisSource:\n  File \"data_modis.py\", line 18, in ModisSource\n    temp_dir = os.environ['MODISPATH']\n  File \"/opt/anaconda3/lib/python3.8/os.py\", line 675, in __getitem__\n    raise KeyError(key) from None\nKeyError: 'MODISPATH'\n",
  "history_begin_time" : 1667950808197,
  "history_end_time" : 1667950810178,
  "history_notes" : null,
  "history_process" : "mxd0ok",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "z0a6kA3Vne6p",
  "history_input" : "from azure.storage.blob import ContainerClient\nimport cv2\nfrom datetime import datetime, timedelta\nimport numpy as np\nimport os\nfrom pyhdf.SD import SD, SDC\nfrom pyproj import Proj,transform\nimport re\nfrom scipy.interpolate import interp2d\nimport wget\n\nclass ModisSource:\n    modis_account_name = 'modissa'\n    modis_container_name = 'modis-006'\n    modis_account_url = 'https://' + modis_account_name + '.blob.core.windows.net/'\n    modis_blob_root = modis_account_url + modis_container_name + '/'\n        \n    temp_dir = os.environ['MODISPATH']\n    if not os.path.isdir(temp_dir):\n        import tempfile\n        temp_dir = os.path.join(tempfile.gettempdir(),'modis')\n        os.makedirs(temp_dir,exist_ok=True)\n    tempfiles = os.listdir(temp_dir)\n    \n    print(f\"data\\\\modis.py: Modis dir is {temp_dir} contain {len(tempfiles)} files\")\n\n    fname = 'sn_bound_10deg.txt'\n    fn = os.path.join(temp_dir, fname)\n    if not os.path.isfile(fn):\n        wget.download(modis_blob_root + fname, fn)\n    \n    # Load this file into a table, where each row is (v,h,lonmin,lonmax,latmin,latmax)\n    modis_tile_extents = np.genfromtxt(fn, skip_header = 7, skip_footer = 3)\n    modis_container_client = ContainerClient(account_url=modis_account_url, \n                                             container_name=modis_container_name,\n                                             credential=None)\n    \ndef lat_lon_to_modis_tiles(lat,lon):\n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    return ModisSource.modis_tile_extents[ok.nonzero()[0], 1::-1].astype(np.int64)\ndef lat_lon_to_modis_tile(lat,lon):\n    \"\"\"\n    Get the modis tile indices (h,v) for a given lat/lon    \n    https://www.earthdatascience.org/tutorials/convert-modis-tile-to-lat-lon/\n    \"\"\"    \n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    i = ok.nonzero()[0]\n    i = i[1] if len(i) >=3 else i[-1]\n    return int(ModisSource.modis_tile_extents[i, 1]),int(ModisSource.modis_tile_extents[i, 0])\n\ndef list_blobs_in_folder(container_name,folder_name):\n    generator = ModisSource.modis_container_client.list_blobs(name_starts_with=folder_name)\n    return [blob.name for blob in generator]\n            \ndef list_hdf_blobs_in_folder(container_name,folder_name):\n    files = list_blobs_in_folder(container_name,folder_name)\n    return [fn for fn in files if fn.endswith('.hdf')]\n\nul_regex = re.compile(r'''UpperLeftPointMtrs=\\(\n                          (?P<upper_left_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<upper_left_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\nlr_regex = re.compile(r'''LowerRightMtrs=\\(\n                          (?P<lower_right_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<lower_right_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\n\n# keys = ['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI']\n# keys = ['NDSI_Snow_Cover', 'NDSI']\nkeys = ['NDSI_Snow_Cover']\nqakey = 'NDSI_Snow_Cover_Basic_QA'\n\ndef calibrate(hdf, keys=None):\n    ga = hdf.attributes()['StructMetadata.0']\n    match = ul_regex.search(ga)\n    x0 = float(match.group('upper_left_x'))\n    y0 = float(match.group('upper_left_y'))\n    match = lr_regex.search(ga)\n    x1 = float(match.group('lower_right_x'))\n    y1 = float(match.group('lower_right_y'))\n    out = {}\n    for key in hdf.datasets():\n        if keys is not None:\n            if key not in keys and key != qakey:\n                continue\n        f = hdf.select(key)\n        data = f.get()\n        attr = f.attributes()    \n        # print(attr)\n        data_c = data.astype(np.float32)\n        if 'scale_factor' in attr:\n            data_c = data_c * float(attr['scale_factor'])            \n        if '_FillValue' in attr:\n            data_c[data==attr['_FillValue']] = np.nan\n        if 'valid_range' in attr:\n            valid_range = attr['valid_range']\n            data_c = np.minimum(np.maximum(data_c, valid_range[0]), valid_range[1])\n        out[key] = data_c\n    qa = out[qakey]==4\n    out['NDSI_Snow_Cover'][qa] = np.nan\n    if qakey not in keys:\n        out.pop(qakey)\n    return out,x0,x1,y0,y1\n    \ndef getmodis_hv(product, h, v, date, verbose=True):\n    # Files are stored according to:\n    # http://modissa.blob.core.windows.net/modis-006/[product]/[htile]/[vtile]/[year][day]/filename\n    # This is the MODIS surface reflectance product\n    folder = product + '/' + '{:0>2d}/{:0>2d}'.format(h,v) + '/' + date.strftime('%Y%j')\n    # Find all HDF files from this tile on this day    \n    # filename = folder+'/'+product+'.A'+date.strftime('%Y%j')+'.h{:0>2d}v{:0>2d}'.format(h,v)+'.006'+\n    filename = folder.replace('/','_')\n    filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    if len(filenames) == 0:\n        ModisSource.tempfiles = os.listdir(ModisSource.temp_dir)\n        filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    ex = False\n    if len(filenames) > 0:        \n        filename = os.path.join(ModisSource.temp_dir,filenames[0])\n        ex = os.path.isfile(filename)\n    if not ex:\n        filenames = list_hdf_blobs_in_folder(ModisSource.modis_container_name,folder)\n        if verbose:\n            print('Found {} matching file(s):'.format(len(filenames)))\n            for fn in filenames:\n                print(fn)    \n        if len(filenames) == 0:\n            return None\n        filename = os.path.join(ModisSource.temp_dir, filenames[0].replace('/','_'))\n        print(filename)\n        if not os.path.isfile(filename):\n            # Download to a temporary file\n            wget.download(ModisSource.modis_blob_root + filenames[0], filename)\n    return SD(filename, SDC.READ)\n\ndef getmodis_lat_lon(product, lat, lon, date, verbose=True):\n    h,v = lat_lon_to_modis_tile(lat,lon)\n    return getmodis_hv(product, h, v, date, verbose)\n\nrgauss = 2.0\ndef getaver (lon,lat,lons,lats,elev,ex,r):\n    ry = r/(1110./(lat.shape[0]-1))\n    mask = (2*int(rgauss*ry)+1, 2*int(rgauss*ry)+1)\n    av = np.nan_to_num(cv2.GaussianBlur(elev, mask, ry)/cv2.GaussianBlur(ex, mask, ry),-9999.)\n    f = interp2d(lon, lat, av, kind='linear')\n    ret = np.array([f(lons[k], lats[k])[0] for k in range(lons.shape[0])])\n    ret[ret<0.] = np.nan\n    return ret\n\nsinu = Proj('+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs')\n# wgs84 = Proj(\"+init=EPSG:4326\")\n# ih = np.array([[8,4],[8,5],[9,4],[9,5],[10,4]])\nih = np.array([[9,5],[8,4],[8,5],[9,4],[10,4]])\ndef getinterpolated(product, lat, lon, date, rads, verbose=False, keys=keys, new=True):    \n    out = {}\n    if keys is not None:\n        if new:\n            for r in rads:\n                out.update({key+str(r): np.full_like(lat, np.nan) for key in keys})\n        else:\n            out.update({key: np.full_like(lat, np.nan) for key in keys})\n    # x, y = transform(wgs84, sinu, lon, lat)\n    x, y = sinu(lon, lat)\n    ihs = [lat_lon_to_modis_tiles(latk,lonk) for lonk,latk in zip(lon,lat)]\n    ih = np.unique(np.concatenate (ihs,0), axis=0)\n    # badhv = np.array([[7,5],[8,4],[11,4]])    \n    for ifile in range(ih.shape[0]):\n        hdf = getmodis_hv(product, ih[ifile][0], ih[ifile][1], date, verbose=False)\n        if hdf is None:\n            continue\n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        sz = m[list(m.keys())[0]].shape\n        ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n        xm = np.linspace(x0,x1,sz[0])\n        ym = np.linspace(y0,y1,sz[1])\n        xs=x[ok]; ys=y[ok]\n        print(f\"ih={ih[ifile]} count={ok.sum()}\")\n        for key in m:\n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                if key+str(r) in out:\n                    v0 = out[key+str(r)][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                out[key+str(r)][ok] = v\n    bad = [key for key in out if np.isnan(out[key]).all()]\n    for key in bad:\n        out.pop(key)\n    if verbose:\n        print([date, {key: np.isfinite(out[key]).sum() for key in out}])\n    return out\n\n# hdf = getmodis_hv('MOD10A1', 8,4,datetime(2003,6,10))\n# m,x0,x1,y0,y1 = calibrate(hdf, keys=['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI'])\ndef getfields(product, date, h, v, out={}, verbose=False, keys=keys):\n    hdf = getmodis_hv(product, h, v, date, verbose=verbose)\n    if hdf is not None:        \n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        out['corners'] = x0,x1,y0,y1\n        for key in m:            \n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            if key in out:\n                out[key] += fld; out[key+'_c'] += ex\n            else:\n                out[key]  = fld; out[key+'_c']  = ex\n            print(f\"{product} {date} {h}_{v} {key} {fld.sum()/ex.sum():.4}\")\n    return out\n\ndef getmeanfields(reqdates, reqdays, loaddates, keys=keys, out = {}):\n    reqdays = [d.replace('-','_') for d in reqdays]    \n    for ifile in range(ih.shape[0]):\n        hvstr = f'f_{ih[ifile][0]}_{ih[ifile][1]}_'\n        for date in loaddates:\n            read = False\n            for date1,tday1 in zip (reqdates, reqdays):\n                if np.abs(((date-date1).days+180)%365-180)<=14:\n                    read = True\n                    break\n            if read:\n                ret = [getfields(product, date, ih[ifile][0], ih[ifile][1], keys=keys) \n                       for product in ['MOD10A1', 'MYD10A1'][:1+(date>=datetime(2002,7,4))]]\n                ret = {key: np.nanmean([r[key] for r in ret if len(r)>0],0) for key in keys+['corners']}\n                for date1,tday1 in zip (reqdates, reqdays):\n                    if np.abs(((date-date1).days+180)%365-180)<=14:\n                        for key in ret:\n                            if key != 'corners':\n                                name = hvstr+tday1+'M'+key\n                                if name in out:\n                                    out[name] = out[name]+ret[key]\n                                else:\n                                    out[name] = ret[key].copy()\n                                # if np.isnan(out[name]).any():\n                                #     print(f\"{name} bads={np.isnan(out[name]).sum()} goods={np.isfinite(out[name]).sum()}\")\n                                # else:\n                                if name[-2:] == '_c':\n                                    print(f\"{name[:-2]} {(out[name[:-2]]/out[name]).mean():.4}\")\n                            elif hvstr+key not in out:\n                                out[hvstr+key] = ret[key]\n    for key in out:\n        if key+'_c' in out:\n            out[key] = out[key]/out[key+'_c']\n    for key in [k for k in out.keys() if k[-2:]=='_c']:\n        out.pop(key)\n    return out\n\ndef interpfields(arx, df, reqdates, reqdays, rads, verbose=False, keys=keys):\n    x, y = sinu(df['longitude'].values, df['latitude'].values)\n    for key in arx:\n        if key[-7:] != 'corners':\n            hvstr = '_'.join(key.split('_')[:3])+'_'\n            x0,x1,y0,y1 = arx[hvstr+'corners']\n            sz = arx[key].shape\n            ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n            xm = np.linspace(x0,x1,sz[0])\n            ym = np.linspace(y0,y1,sz[1])\n            xs=x[ok]; ys=y[ok]\n            print(f\"{key} count={ok.sum()}\")\n            ex = np.isfinite(arx[key]).astype(np.float32)\n            fld = np.nan_to_num(arx[key],0.)\n            key1 = key[len(hvstr):]\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                name = key1[:10].replace('_','-')+key1[10:]+str(r)\n                if name in df:\n                    v0 = df[name][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                else:\n                    df[name] = np.full_like(x, np.nan)\n                df[name][ok] = v\n    return df\n\nif __name__ == '__main__':\n    # import geojson\n    # import pandas as pd\n    # from os import path\n    # workdir = 'evaluation'\n    # # workdir = 'development'\n    # with open(path.join(workdir,'grid_cells.geojson')) as f:\n    #     grid = geojson.load(f)\n    # grid = pd.DataFrame([{'cell_id':g['properties']['cell_id'], 'region':g['properties']['region'], \n    #                       'corners': np.array(g['geometry']['coordinates'])} for g in grid['features']]).set_index('cell_id')\n    # gll = np.vstack(grid['corners'].values)    \n    # grid['latitude'] = gll[:,:,1].mean(1)\n    # grid['longitude'] = gll[:,:,0].mean(1)\n    # stmeta = pd.read_csv(path.join(workdir,'ground_measures_metadata.csv')).set_index('station_id')\n    \n    import matplotlib.pyplot as plt\n    file = getmodis_lat_lon('MYD10A1', 41.881832, -87.623177, datetime(2010, 5, 15))\n    print(list(file.datasets().keys()))    \n    rgb,x0,x1,y0,y1 = calibrate(file)\n    for key in rgb:\n        fig = plt.figure(frameon=False); ax = plt.Axes(fig,[0., 0., 1., 1.])\n        ax.set_axis_off(); fig.add_axes(ax)\n        plt.imshow(rgb[key])\n        ax.set_title(key)",
  "history_output" : "Traceback (most recent call last):\n  File \"data_modis.py\", line 12, in <module>\n    class ModisSource:\n  File \"data_modis.py\", line 18, in ModisSource\n    temp_dir = os.environ['MODISPATH']\n  File \"/opt/anaconda3/lib/python3.8/os.py\", line 675, in __getitem__\n    raise KeyError(key) from None\nKeyError: 'MODISPATH'\n",
  "history_begin_time" : 1667949246125,
  "history_end_time" : 1667949247277,
  "history_notes" : null,
  "history_process" : "mxd0ok",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "CVYmWiV1Ovrl",
  "history_input" : "from azure.storage.blob import ContainerClient\nimport cv2\nfrom datetime import datetime, timedelta\nimport numpy as np\nimport os\nfrom pyhdf.SD import SD, SDC\nfrom pyproj import Proj,transform\nimport re\nfrom scipy.interpolate import interp2d\nimport wget\n\nclass ModisSource:\n    modis_account_name = 'modissa'\n    modis_container_name = 'modis-006'\n    modis_account_url = 'https://' + modis_account_name + '.blob.core.windows.net/'\n    modis_blob_root = modis_account_url + modis_container_name + '/'\n        \n    temp_dir = os.environ['MODISPATH']\n    if not os.path.isdir(temp_dir):\n        import tempfile\n        temp_dir = os.path.join(tempfile.gettempdir(),'modis')\n        os.makedirs(temp_dir,exist_ok=True)\n    tempfiles = os.listdir(temp_dir)\n    \n    print(f\"data\\\\modis.py: Modis dir is {temp_dir} contain {len(tempfiles)} files\")\n\n    fname = 'sn_bound_10deg.txt'\n    fn = os.path.join(temp_dir, fname)\n    if not os.path.isfile(fn):\n        wget.download(modis_blob_root + fname, fn)\n    \n    # Load this file into a table, where each row is (v,h,lonmin,lonmax,latmin,latmax)\n    modis_tile_extents = np.genfromtxt(fn, skip_header = 7, skip_footer = 3)\n    modis_container_client = ContainerClient(account_url=modis_account_url, \n                                             container_name=modis_container_name,\n                                             credential=None)\n    \ndef lat_lon_to_modis_tiles(lat,lon):\n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    return ModisSource.modis_tile_extents[ok.nonzero()[0], 1::-1].astype(np.int64)\ndef lat_lon_to_modis_tile(lat,lon):\n    \"\"\"\n    Get the modis tile indices (h,v) for a given lat/lon    \n    https://www.earthdatascience.org/tutorials/convert-modis-tile-to-lat-lon/\n    \"\"\"    \n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    i = ok.nonzero()[0]\n    i = i[1] if len(i) >=3 else i[-1]\n    return int(ModisSource.modis_tile_extents[i, 1]),int(ModisSource.modis_tile_extents[i, 0])\n\ndef list_blobs_in_folder(container_name,folder_name):\n    generator = ModisSource.modis_container_client.list_blobs(name_starts_with=folder_name)\n    return [blob.name for blob in generator]\n            \ndef list_hdf_blobs_in_folder(container_name,folder_name):\n    files = list_blobs_in_folder(container_name,folder_name)\n    return [fn for fn in files if fn.endswith('.hdf')]\n\nul_regex = re.compile(r'''UpperLeftPointMtrs=\\(\n                          (?P<upper_left_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<upper_left_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\nlr_regex = re.compile(r'''LowerRightMtrs=\\(\n                          (?P<lower_right_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<lower_right_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\n\n# keys = ['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI']\n# keys = ['NDSI_Snow_Cover', 'NDSI']\nkeys = ['NDSI_Snow_Cover']\nqakey = 'NDSI_Snow_Cover_Basic_QA'\n\ndef calibrate(hdf, keys=None):\n    ga = hdf.attributes()['StructMetadata.0']\n    match = ul_regex.search(ga)\n    x0 = float(match.group('upper_left_x'))\n    y0 = float(match.group('upper_left_y'))\n    match = lr_regex.search(ga)\n    x1 = float(match.group('lower_right_x'))\n    y1 = float(match.group('lower_right_y'))\n    out = {}\n    for key in hdf.datasets():\n        if keys is not None:\n            if key not in keys and key != qakey:\n                continue\n        f = hdf.select(key)\n        data = f.get()\n        attr = f.attributes()    \n        # print(attr)\n        data_c = data.astype(np.float32)\n        if 'scale_factor' in attr:\n            data_c = data_c * float(attr['scale_factor'])            \n        if '_FillValue' in attr:\n            data_c[data==attr['_FillValue']] = np.nan\n        if 'valid_range' in attr:\n            valid_range = attr['valid_range']\n            data_c = np.minimum(np.maximum(data_c, valid_range[0]), valid_range[1])\n        out[key] = data_c\n    qa = out[qakey]==4\n    out['NDSI_Snow_Cover'][qa] = np.nan\n    if qakey not in keys:\n        out.pop(qakey)\n    return out,x0,x1,y0,y1\n    \ndef getmodis_hv(product, h, v, date, verbose=True):\n    # Files are stored according to:\n    # http://modissa.blob.core.windows.net/modis-006/[product]/[htile]/[vtile]/[year][day]/filename\n    # This is the MODIS surface reflectance product\n    folder = product + '/' + '{:0>2d}/{:0>2d}'.format(h,v) + '/' + date.strftime('%Y%j')\n    # Find all HDF files from this tile on this day    \n    # filename = folder+'/'+product+'.A'+date.strftime('%Y%j')+'.h{:0>2d}v{:0>2d}'.format(h,v)+'.006'+\n    filename = folder.replace('/','_')\n    filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    if len(filenames) == 0:\n        ModisSource.tempfiles = os.listdir(ModisSource.temp_dir)\n        filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    ex = False\n    if len(filenames) > 0:        \n        filename = os.path.join(ModisSource.temp_dir,filenames[0])\n        ex = os.path.isfile(filename)\n    if not ex:\n        filenames = list_hdf_blobs_in_folder(ModisSource.modis_container_name,folder)\n        if verbose:\n            print('Found {} matching file(s):'.format(len(filenames)))\n            for fn in filenames:\n                print(fn)    \n        if len(filenames) == 0:\n            return None\n        filename = os.path.join(ModisSource.temp_dir, filenames[0].replace('/','_'))\n        print(filename)\n        if not os.path.isfile(filename):\n            # Download to a temporary file\n            wget.download(ModisSource.modis_blob_root + filenames[0], filename)\n    return SD(filename, SDC.READ)\n\ndef getmodis_lat_lon(product, lat, lon, date, verbose=True):\n    h,v = lat_lon_to_modis_tile(lat,lon)\n    return getmodis_hv(product, h, v, date, verbose)\n\nrgauss = 2.0\ndef getaver (lon,lat,lons,lats,elev,ex,r):\n    ry = r/(1110./(lat.shape[0]-1))\n    mask = (2*int(rgauss*ry)+1, 2*int(rgauss*ry)+1)\n    av = np.nan_to_num(cv2.GaussianBlur(elev, mask, ry)/cv2.GaussianBlur(ex, mask, ry),-9999.)\n    f = interp2d(lon, lat, av, kind='linear')\n    ret = np.array([f(lons[k], lats[k])[0] for k in range(lons.shape[0])])\n    ret[ret<0.] = np.nan\n    return ret\n\nsinu = Proj('+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs')\n# wgs84 = Proj(\"+init=EPSG:4326\")\n# ih = np.array([[8,4],[8,5],[9,4],[9,5],[10,4]])\nih = np.array([[9,5],[8,4],[8,5],[9,4],[10,4]])\ndef getinterpolated(product, lat, lon, date, rads, verbose=False, keys=keys, new=True):    \n    out = {}\n    if keys is not None:\n        if new:\n            for r in rads:\n                out.update({key+str(r): np.full_like(lat, np.nan) for key in keys})\n        else:\n            out.update({key: np.full_like(lat, np.nan) for key in keys})\n    # x, y = transform(wgs84, sinu, lon, lat)\n    x, y = sinu(lon, lat)\n    ihs = [lat_lon_to_modis_tiles(latk,lonk) for lonk,latk in zip(lon,lat)]\n    ih = np.unique(np.concatenate (ihs,0), axis=0)\n    # badhv = np.array([[7,5],[8,4],[11,4]])    \n    for ifile in range(ih.shape[0]):\n        hdf = getmodis_hv(product, ih[ifile][0], ih[ifile][1], date, verbose=False)\n        if hdf is None:\n            continue\n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        sz = m[list(m.keys())[0]].shape\n        ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n        xm = np.linspace(x0,x1,sz[0])\n        ym = np.linspace(y0,y1,sz[1])\n        xs=x[ok]; ys=y[ok]\n        print(f\"ih={ih[ifile]} count={ok.sum()}\")\n        for key in m:\n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                if key+str(r) in out:\n                    v0 = out[key+str(r)][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                out[key+str(r)][ok] = v\n    bad = [key for key in out if np.isnan(out[key]).all()]\n    for key in bad:\n        out.pop(key)\n    if verbose:\n        print([date, {key: np.isfinite(out[key]).sum() for key in out}])\n    return out\n\n# hdf = getmodis_hv('MOD10A1', 8,4,datetime(2003,6,10))\n# m,x0,x1,y0,y1 = calibrate(hdf, keys=['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI'])\ndef getfields(product, date, h, v, out={}, verbose=False, keys=keys):\n    hdf = getmodis_hv(product, h, v, date, verbose=verbose)\n    if hdf is not None:        \n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        out['corners'] = x0,x1,y0,y1\n        for key in m:            \n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            if key in out:\n                out[key] += fld; out[key+'_c'] += ex\n            else:\n                out[key]  = fld; out[key+'_c']  = ex\n            print(f\"{product} {date} {h}_{v} {key} {fld.sum()/ex.sum():.4}\")\n    return out\n\ndef getmeanfields(reqdates, reqdays, loaddates, keys=keys, out = {}):\n    reqdays = [d.replace('-','_') for d in reqdays]    \n    for ifile in range(ih.shape[0]):\n        hvstr = f'f_{ih[ifile][0]}_{ih[ifile][1]}_'\n        for date in loaddates:\n            read = False\n            for date1,tday1 in zip (reqdates, reqdays):\n                if np.abs(((date-date1).days+180)%365-180)<=14:\n                    read = True\n                    break\n            if read:\n                ret = [getfields(product, date, ih[ifile][0], ih[ifile][1], keys=keys) \n                       for product in ['MOD10A1', 'MYD10A1'][:1+(date>=datetime(2002,7,4))]]\n                ret = {key: np.nanmean([r[key] for r in ret if len(r)>0],0) for key in keys+['corners']}\n                for date1,tday1 in zip (reqdates, reqdays):\n                    if np.abs(((date-date1).days+180)%365-180)<=14:\n                        for key in ret:\n                            if key != 'corners':\n                                name = hvstr+tday1+'M'+key\n                                if name in out:\n                                    out[name] = out[name]+ret[key]\n                                else:\n                                    out[name] = ret[key].copy()\n                                # if np.isnan(out[name]).any():\n                                #     print(f\"{name} bads={np.isnan(out[name]).sum()} goods={np.isfinite(out[name]).sum()}\")\n                                # else:\n                                if name[-2:] == '_c':\n                                    print(f\"{name[:-2]} {(out[name[:-2]]/out[name]).mean():.4}\")\n                            elif hvstr+key not in out:\n                                out[hvstr+key] = ret[key]\n    for key in out:\n        if key+'_c' in out:\n            out[key] = out[key]/out[key+'_c']\n    for key in [k for k in out.keys() if k[-2:]=='_c']:\n        out.pop(key)\n    return out\n\ndef interpfields(arx, df, reqdates, reqdays, rads, verbose=False, keys=keys):\n    x, y = sinu(df['longitude'].values, df['latitude'].values)\n    for key in arx:\n        if key[-7:] != 'corners':\n            hvstr = '_'.join(key.split('_')[:3])+'_'\n            x0,x1,y0,y1 = arx[hvstr+'corners']\n            sz = arx[key].shape\n            ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n            xm = np.linspace(x0,x1,sz[0])\n            ym = np.linspace(y0,y1,sz[1])\n            xs=x[ok]; ys=y[ok]\n            print(f\"{key} count={ok.sum()}\")\n            ex = np.isfinite(arx[key]).astype(np.float32)\n            fld = np.nan_to_num(arx[key],0.)\n            key1 = key[len(hvstr):]\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                name = key1[:10].replace('_','-')+key1[10:]+str(r)\n                if name in df:\n                    v0 = df[name][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                else:\n                    df[name] = np.full_like(x, np.nan)\n                df[name][ok] = v\n    return df\n\nif __name__ == '__main__':\n    # import geojson\n    # import pandas as pd\n    # from os import path\n    # workdir = 'evaluation'\n    # # workdir = 'development'\n    # with open(path.join(workdir,'grid_cells.geojson')) as f:\n    #     grid = geojson.load(f)\n    # grid = pd.DataFrame([{'cell_id':g['properties']['cell_id'], 'region':g['properties']['region'], \n    #                       'corners': np.array(g['geometry']['coordinates'])} for g in grid['features']]).set_index('cell_id')\n    # gll = np.vstack(grid['corners'].values)    \n    # grid['latitude'] = gll[:,:,1].mean(1)\n    # grid['longitude'] = gll[:,:,0].mean(1)\n    # stmeta = pd.read_csv(path.join(workdir,'ground_measures_metadata.csv')).set_index('station_id')\n    \n    import matplotlib.pyplot as plt\n    file = getmodis_lat_lon('MYD10A1', 41.881832, -87.623177, datetime(2010, 5, 15))\n    print(list(file.datasets().keys()))    \n    rgb,x0,x1,y0,y1 = calibrate(file)\n    for key in rgb:\n        fig = plt.figure(frameon=False); ax = plt.Axes(fig,[0., 0., 1., 1.])\n        ax.set_axis_off(); fig.add_axes(ax)\n        plt.imshow(rgb[key])\n        ax.set_title(key)",
  "history_output" : "Traceback (most recent call last):\n  File \"data_modis.py\", line 12, in <module>\n    class ModisSource:\n  File \"data_modis.py\", line 18, in ModisSource\n    temp_dir = os.environ['MODISPATH']\n  File \"/opt/anaconda3/lib/python3.8/os.py\", line 675, in __getitem__\n    raise KeyError(key) from None\nKeyError: 'MODISPATH'\n",
  "history_begin_time" : 1667949185018,
  "history_end_time" : 1667949186955,
  "history_notes" : null,
  "history_process" : "mxd0ok",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "XvbOlyLjAo6x",
  "history_input" : "from azure.storage.blob import ContainerClient\nimport cv2\nfrom datetime import datetime, timedelta\nimport numpy as np\nimport os\nfrom pyhdf.SD import SD, SDC\nfrom pyproj import Proj,transform\nimport re\nfrom scipy.interpolate import interp2d\nimport wget\n\nclass ModisSource:\n    modis_account_name = 'modissa'\n    modis_container_name = 'modis-006'\n    modis_account_url = 'https://' + modis_account_name + '.blob.core.windows.net/'\n    modis_blob_root = modis_account_url + modis_container_name + '/'\n        \n    temp_dir = os.environ['MODISPATH']\n    if not os.path.isdir(temp_dir):\n        import tempfile\n        temp_dir = os.path.join(tempfile.gettempdir(),'modis')\n        os.makedirs(temp_dir,exist_ok=True)\n    tempfiles = os.listdir(temp_dir)\n    \n    print(f\"data\\\\modis.py: Modis dir is {temp_dir} contain {len(tempfiles)} files\")\n\n    fname = 'sn_bound_10deg.txt'\n    fn = os.path.join(temp_dir, fname)\n    if not os.path.isfile(fn):\n        wget.download(modis_blob_root + fname, fn)\n    \n    # Load this file into a table, where each row is (v,h,lonmin,lonmax,latmin,latmax)\n    modis_tile_extents = np.genfromtxt(fn, skip_header = 7, skip_footer = 3)\n    modis_container_client = ContainerClient(account_url=modis_account_url, \n                                             container_name=modis_container_name,\n                                             credential=None)\n    \ndef lat_lon_to_modis_tiles(lat,lon):\n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    return ModisSource.modis_tile_extents[ok.nonzero()[0], 1::-1].astype(np.int64)\ndef lat_lon_to_modis_tile(lat,lon):\n    \"\"\"\n    Get the modis tile indices (h,v) for a given lat/lon    \n    https://www.earthdatascience.org/tutorials/convert-modis-tile-to-lat-lon/\n    \"\"\"    \n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    i = ok.nonzero()[0]\n    i = i[1] if len(i) >=3 else i[-1]\n    return int(ModisSource.modis_tile_extents[i, 1]),int(ModisSource.modis_tile_extents[i, 0])\n\ndef list_blobs_in_folder(container_name,folder_name):\n    generator = ModisSource.modis_container_client.list_blobs(name_starts_with=folder_name)\n    return [blob.name for blob in generator]\n            \ndef list_hdf_blobs_in_folder(container_name,folder_name):\n    files = list_blobs_in_folder(container_name,folder_name)\n    return [fn for fn in files if fn.endswith('.hdf')]\n\nul_regex = re.compile(r'''UpperLeftPointMtrs=\\(\n                          (?P<upper_left_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<upper_left_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\nlr_regex = re.compile(r'''LowerRightMtrs=\\(\n                          (?P<lower_right_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<lower_right_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\n\n# keys = ['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI']\n# keys = ['NDSI_Snow_Cover', 'NDSI']\nkeys = ['NDSI_Snow_Cover']\nqakey = 'NDSI_Snow_Cover_Basic_QA'\n\ndef calibrate(hdf, keys=None):\n    ga = hdf.attributes()['StructMetadata.0']\n    match = ul_regex.search(ga)\n    x0 = float(match.group('upper_left_x'))\n    y0 = float(match.group('upper_left_y'))\n    match = lr_regex.search(ga)\n    x1 = float(match.group('lower_right_x'))\n    y1 = float(match.group('lower_right_y'))\n    out = {}\n    for key in hdf.datasets():\n        if keys is not None:\n            if key not in keys and key != qakey:\n                continue\n        f = hdf.select(key)\n        data = f.get()\n        attr = f.attributes()    \n        # print(attr)\n        data_c = data.astype(np.float32)\n        if 'scale_factor' in attr:\n            data_c = data_c * float(attr['scale_factor'])            \n        if '_FillValue' in attr:\n            data_c[data==attr['_FillValue']] = np.nan\n        if 'valid_range' in attr:\n            valid_range = attr['valid_range']\n            data_c = np.minimum(np.maximum(data_c, valid_range[0]), valid_range[1])\n        out[key] = data_c\n    qa = out[qakey]==4\n    out['NDSI_Snow_Cover'][qa] = np.nan\n    if qakey not in keys:\n        out.pop(qakey)\n    return out,x0,x1,y0,y1\n    \ndef getmodis_hv(product, h, v, date, verbose=True):\n    # Files are stored according to:\n    # http://modissa.blob.core.windows.net/modis-006/[product]/[htile]/[vtile]/[year][day]/filename\n    # This is the MODIS surface reflectance product\n    folder = product + '/' + '{:0>2d}/{:0>2d}'.format(h,v) + '/' + date.strftime('%Y%j')\n    # Find all HDF files from this tile on this day    \n    # filename = folder+'/'+product+'.A'+date.strftime('%Y%j')+'.h{:0>2d}v{:0>2d}'.format(h,v)+'.006'+\n    filename = folder.replace('/','_')\n    filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    if len(filenames) == 0:\n        ModisSource.tempfiles = os.listdir(ModisSource.temp_dir)\n        filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    ex = False\n    if len(filenames) > 0:        \n        filename = os.path.join(ModisSource.temp_dir,filenames[0])\n        ex = os.path.isfile(filename)\n    if not ex:\n        filenames = list_hdf_blobs_in_folder(ModisSource.modis_container_name,folder)\n        if verbose:\n            print('Found {} matching file(s):'.format(len(filenames)))\n            for fn in filenames:\n                print(fn)    \n        if len(filenames) == 0:\n            return None\n        filename = os.path.join(ModisSource.temp_dir, filenames[0].replace('/','_'))\n        print(filename)\n        if not os.path.isfile(filename):\n            # Download to a temporary file\n            wget.download(ModisSource.modis_blob_root + filenames[0], filename)\n    return SD(filename, SDC.READ)\n\ndef getmodis_lat_lon(product, lat, lon, date, verbose=True):\n    h,v = lat_lon_to_modis_tile(lat,lon)\n    return getmodis_hv(product, h, v, date, verbose)\n\nrgauss = 2.0\ndef getaver (lon,lat,lons,lats,elev,ex,r):\n    ry = r/(1110./(lat.shape[0]-1))\n    mask = (2*int(rgauss*ry)+1, 2*int(rgauss*ry)+1)\n    av = np.nan_to_num(cv2.GaussianBlur(elev, mask, ry)/cv2.GaussianBlur(ex, mask, ry),-9999.)\n    f = interp2d(lon, lat, av, kind='linear')\n    ret = np.array([f(lons[k], lats[k])[0] for k in range(lons.shape[0])])\n    ret[ret<0.] = np.nan\n    return ret\n\nsinu = Proj('+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs')\n# wgs84 = Proj(\"+init=EPSG:4326\")\n# ih = np.array([[8,4],[8,5],[9,4],[9,5],[10,4]])\nih = np.array([[9,5],[8,4],[8,5],[9,4],[10,4]])\ndef getinterpolated(product, lat, lon, date, rads, verbose=False, keys=keys, new=True):    \n    out = {}\n    if keys is not None:\n        if new:\n            for r in rads:\n                out.update({key+str(r): np.full_like(lat, np.nan) for key in keys})\n        else:\n            out.update({key: np.full_like(lat, np.nan) for key in keys})\n    # x, y = transform(wgs84, sinu, lon, lat)\n    x, y = sinu(lon, lat)\n    ihs = [lat_lon_to_modis_tiles(latk,lonk) for lonk,latk in zip(lon,lat)]\n    ih = np.unique(np.concatenate (ihs,0), axis=0)\n    # badhv = np.array([[7,5],[8,4],[11,4]])    \n    for ifile in range(ih.shape[0]):\n        hdf = getmodis_hv(product, ih[ifile][0], ih[ifile][1], date, verbose=False)\n        if hdf is None:\n            continue\n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        sz = m[list(m.keys())[0]].shape\n        ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n        xm = np.linspace(x0,x1,sz[0])\n        ym = np.linspace(y0,y1,sz[1])\n        xs=x[ok]; ys=y[ok]\n        print(f\"ih={ih[ifile]} count={ok.sum()}\")\n        for key in m:\n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                if key+str(r) in out:\n                    v0 = out[key+str(r)][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                out[key+str(r)][ok] = v\n    bad = [key for key in out if np.isnan(out[key]).all()]\n    for key in bad:\n        out.pop(key)\n    if verbose:\n        print([date, {key: np.isfinite(out[key]).sum() for key in out}])\n    return out\n\n# hdf = getmodis_hv('MOD10A1', 8,4,datetime(2003,6,10))\n# m,x0,x1,y0,y1 = calibrate(hdf, keys=['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI'])\ndef getfields(product, date, h, v, out={}, verbose=False, keys=keys):\n    hdf = getmodis_hv(product, h, v, date, verbose=verbose)\n    if hdf is not None:        \n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        out['corners'] = x0,x1,y0,y1\n        for key in m:            \n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            if key in out:\n                out[key] += fld; out[key+'_c'] += ex\n            else:\n                out[key]  = fld; out[key+'_c']  = ex\n            print(f\"{product} {date} {h}_{v} {key} {fld.sum()/ex.sum():.4}\")\n    return out\n\ndef getmeanfields(reqdates, reqdays, loaddates, keys=keys, out = {}):\n    reqdays = [d.replace('-','_') for d in reqdays]    \n    for ifile in range(ih.shape[0]):\n        hvstr = f'f_{ih[ifile][0]}_{ih[ifile][1]}_'\n        for date in loaddates:\n            read = False\n            for date1,tday1 in zip (reqdates, reqdays):\n                if np.abs(((date-date1).days+180)%365-180)<=14:\n                    read = True\n                    break\n            if read:\n                ret = [getfields(product, date, ih[ifile][0], ih[ifile][1], keys=keys) \n                       for product in ['MOD10A1', 'MYD10A1'][:1+(date>=datetime(2002,7,4))]]\n                ret = {key: np.nanmean([r[key] for r in ret if len(r)>0],0) for key in keys+['corners']}\n                for date1,tday1 in zip (reqdates, reqdays):\n                    if np.abs(((date-date1).days+180)%365-180)<=14:\n                        for key in ret:\n                            if key != 'corners':\n                                name = hvstr+tday1+'M'+key\n                                if name in out:\n                                    out[name] = out[name]+ret[key]\n                                else:\n                                    out[name] = ret[key].copy()\n                                # if np.isnan(out[name]).any():\n                                #     print(f\"{name} bads={np.isnan(out[name]).sum()} goods={np.isfinite(out[name]).sum()}\")\n                                # else:\n                                if name[-2:] == '_c':\n                                    print(f\"{name[:-2]} {(out[name[:-2]]/out[name]).mean():.4}\")\n                            elif hvstr+key not in out:\n                                out[hvstr+key] = ret[key]\n    for key in out:\n        if key+'_c' in out:\n            out[key] = out[key]/out[key+'_c']\n    for key in [k for k in out.keys() if k[-2:]=='_c']:\n        out.pop(key)\n    return out\n\ndef interpfields(arx, df, reqdates, reqdays, rads, verbose=False, keys=keys):\n    x, y = sinu(df['longitude'].values, df['latitude'].values)\n    for key in arx:\n        if key[-7:] != 'corners':\n            hvstr = '_'.join(key.split('_')[:3])+'_'\n            x0,x1,y0,y1 = arx[hvstr+'corners']\n            sz = arx[key].shape\n            ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n            xm = np.linspace(x0,x1,sz[0])\n            ym = np.linspace(y0,y1,sz[1])\n            xs=x[ok]; ys=y[ok]\n            print(f\"{key} count={ok.sum()}\")\n            ex = np.isfinite(arx[key]).astype(np.float32)\n            fld = np.nan_to_num(arx[key],0.)\n            key1 = key[len(hvstr):]\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                name = key1[:10].replace('_','-')+key1[10:]+str(r)\n                if name in df:\n                    v0 = df[name][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                else:\n                    df[name] = np.full_like(x, np.nan)\n                df[name][ok] = v\n    return df\n\nif __name__ == '__main__':\n    # import geojson\n    # import pandas as pd\n    # from os import path\n    # workdir = 'evaluation'\n    # # workdir = 'development'\n    # with open(path.join(workdir,'grid_cells.geojson')) as f:\n    #     grid = geojson.load(f)\n    # grid = pd.DataFrame([{'cell_id':g['properties']['cell_id'], 'region':g['properties']['region'], \n    #                       'corners': np.array(g['geometry']['coordinates'])} for g in grid['features']]).set_index('cell_id')\n    # gll = np.vstack(grid['corners'].values)    \n    # grid['latitude'] = gll[:,:,1].mean(1)\n    # grid['longitude'] = gll[:,:,0].mean(1)\n    # stmeta = pd.read_csv(path.join(workdir,'ground_measures_metadata.csv')).set_index('station_id')\n    \n    import matplotlib.pyplot as plt\n    file = getmodis_lat_lon('MYD10A1', 41.881832, -87.623177, datetime(2010, 5, 15))\n    print(list(file.datasets().keys()))    \n    rgb,x0,x1,y0,y1 = calibrate(file)\n    for key in rgb:\n        fig = plt.figure(frameon=False); ax = plt.Axes(fig,[0., 0., 1., 1.])\n        ax.set_axis_off(); fig.add_axes(ax)\n        plt.imshow(rgb[key])\n        ax.set_title(key)",
  "history_output" : "Traceback (most recent call last):\n  File \"data_modis.py\", line 6, in <module>\n    from pyhdf.SD import SD, SDC\nModuleNotFoundError: No module named 'pyhdf'\n",
  "history_begin_time" : 1667949157408,
  "history_end_time" : 1667949158737,
  "history_notes" : null,
  "history_process" : "mxd0ok",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "WrgF2tTyxsCu",
  "history_input" : "from azure.storage.blob import ContainerClient\nimport cv2\nfrom datetime import datetime, timedelta\nimport numpy as np\nimport os\nfrom pyhdf.SD import SD, SDC\nfrom pyproj import Proj,transform\nimport re\nfrom scipy.interpolate import interp2d\nimport wget\n\nclass ModisSource:\n    modis_account_name = 'modissa'\n    modis_container_name = 'modis-006'\n    modis_account_url = 'https://' + modis_account_name + '.blob.core.windows.net/'\n    modis_blob_root = modis_account_url + modis_container_name + '/'\n        \n    temp_dir = os.environ['MODISPATH']\n    if not os.path.isdir(temp_dir):\n        import tempfile\n        temp_dir = os.path.join(tempfile.gettempdir(),'modis')\n        os.makedirs(temp_dir,exist_ok=True)\n    tempfiles = os.listdir(temp_dir)\n    \n    print(f\"data\\\\modis.py: Modis dir is {temp_dir} contain {len(tempfiles)} files\")\n\n    fname = 'sn_bound_10deg.txt'\n    fn = os.path.join(temp_dir, fname)\n    if not os.path.isfile(fn):\n        wget.download(modis_blob_root + fname, fn)\n    \n    # Load this file into a table, where each row is (v,h,lonmin,lonmax,latmin,latmax)\n    modis_tile_extents = np.genfromtxt(fn, skip_header = 7, skip_footer = 3)\n    modis_container_client = ContainerClient(account_url=modis_account_url, \n                                             container_name=modis_container_name,\n                                             credential=None)\n    \ndef lat_lon_to_modis_tiles(lat,lon):\n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    return ModisSource.modis_tile_extents[ok.nonzero()[0], 1::-1].astype(np.int64)\ndef lat_lon_to_modis_tile(lat,lon):\n    \"\"\"\n    Get the modis tile indices (h,v) for a given lat/lon    \n    https://www.earthdatascience.org/tutorials/convert-modis-tile-to-lat-lon/\n    \"\"\"    \n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    i = ok.nonzero()[0]\n    i = i[1] if len(i) >=3 else i[-1]\n    return int(ModisSource.modis_tile_extents[i, 1]),int(ModisSource.modis_tile_extents[i, 0])\n\ndef list_blobs_in_folder(container_name,folder_name):\n    generator = ModisSource.modis_container_client.list_blobs(name_starts_with=folder_name)\n    return [blob.name for blob in generator]\n            \ndef list_hdf_blobs_in_folder(container_name,folder_name):\n    files = list_blobs_in_folder(container_name,folder_name)\n    return [fn for fn in files if fn.endswith('.hdf')]\n\nul_regex = re.compile(r'''UpperLeftPointMtrs=\\(\n                          (?P<upper_left_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<upper_left_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\nlr_regex = re.compile(r'''LowerRightMtrs=\\(\n                          (?P<lower_right_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<lower_right_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\n\n# keys = ['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI']\n# keys = ['NDSI_Snow_Cover', 'NDSI']\nkeys = ['NDSI_Snow_Cover']\nqakey = 'NDSI_Snow_Cover_Basic_QA'\n\ndef calibrate(hdf, keys=None):\n    ga = hdf.attributes()['StructMetadata.0']\n    match = ul_regex.search(ga)\n    x0 = float(match.group('upper_left_x'))\n    y0 = float(match.group('upper_left_y'))\n    match = lr_regex.search(ga)\n    x1 = float(match.group('lower_right_x'))\n    y1 = float(match.group('lower_right_y'))\n    out = {}\n    for key in hdf.datasets():\n        if keys is not None:\n            if key not in keys and key != qakey:\n                continue\n        f = hdf.select(key)\n        data = f.get()\n        attr = f.attributes()    \n        # print(attr)\n        data_c = data.astype(np.float32)\n        if 'scale_factor' in attr:\n            data_c = data_c * float(attr['scale_factor'])            \n        if '_FillValue' in attr:\n            data_c[data==attr['_FillValue']] = np.nan\n        if 'valid_range' in attr:\n            valid_range = attr['valid_range']\n            data_c = np.minimum(np.maximum(data_c, valid_range[0]), valid_range[1])\n        out[key] = data_c\n    qa = out[qakey]==4\n    out['NDSI_Snow_Cover'][qa] = np.nan\n    if qakey not in keys:\n        out.pop(qakey)\n    return out,x0,x1,y0,y1\n    \ndef getmodis_hv(product, h, v, date, verbose=True):\n    # Files are stored according to:\n    # http://modissa.blob.core.windows.net/modis-006/[product]/[htile]/[vtile]/[year][day]/filename\n    # This is the MODIS surface reflectance product\n    folder = product + '/' + '{:0>2d}/{:0>2d}'.format(h,v) + '/' + date.strftime('%Y%j')\n    # Find all HDF files from this tile on this day    \n    # filename = folder+'/'+product+'.A'+date.strftime('%Y%j')+'.h{:0>2d}v{:0>2d}'.format(h,v)+'.006'+\n    filename = folder.replace('/','_')\n    filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    if len(filenames) == 0:\n        ModisSource.tempfiles = os.listdir(ModisSource.temp_dir)\n        filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    ex = False\n    if len(filenames) > 0:        \n        filename = os.path.join(ModisSource.temp_dir,filenames[0])\n        ex = os.path.isfile(filename)\n    if not ex:\n        filenames = list_hdf_blobs_in_folder(ModisSource.modis_container_name,folder)\n        if verbose:\n            print('Found {} matching file(s):'.format(len(filenames)))\n            for fn in filenames:\n                print(fn)    \n        if len(filenames) == 0:\n            return None\n        filename = os.path.join(ModisSource.temp_dir, filenames[0].replace('/','_'))\n        print(filename)\n        if not os.path.isfile(filename):\n            # Download to a temporary file\n            wget.download(ModisSource.modis_blob_root + filenames[0], filename)\n    return SD(filename, SDC.READ)\n\ndef getmodis_lat_lon(product, lat, lon, date, verbose=True):\n    h,v = lat_lon_to_modis_tile(lat,lon)\n    return getmodis_hv(product, h, v, date, verbose)\n\nrgauss = 2.0\ndef getaver (lon,lat,lons,lats,elev,ex,r):\n    ry = r/(1110./(lat.shape[0]-1))\n    mask = (2*int(rgauss*ry)+1, 2*int(rgauss*ry)+1)\n    av = np.nan_to_num(cv2.GaussianBlur(elev, mask, ry)/cv2.GaussianBlur(ex, mask, ry),-9999.)\n    f = interp2d(lon, lat, av, kind='linear')\n    ret = np.array([f(lons[k], lats[k])[0] for k in range(lons.shape[0])])\n    ret[ret<0.] = np.nan\n    return ret\n\nsinu = Proj('+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs')\n# wgs84 = Proj(\"+init=EPSG:4326\")\n# ih = np.array([[8,4],[8,5],[9,4],[9,5],[10,4]])\nih = np.array([[9,5],[8,4],[8,5],[9,4],[10,4]])\ndef getinterpolated(product, lat, lon, date, rads, verbose=False, keys=keys, new=True):    \n    out = {}\n    if keys is not None:\n        if new:\n            for r in rads:\n                out.update({key+str(r): np.full_like(lat, np.nan) for key in keys})\n        else:\n            out.update({key: np.full_like(lat, np.nan) for key in keys})\n    # x, y = transform(wgs84, sinu, lon, lat)\n    x, y = sinu(lon, lat)\n    ihs = [lat_lon_to_modis_tiles(latk,lonk) for lonk,latk in zip(lon,lat)]\n    ih = np.unique(np.concatenate (ihs,0), axis=0)\n    # badhv = np.array([[7,5],[8,4],[11,4]])    \n    for ifile in range(ih.shape[0]):\n        hdf = getmodis_hv(product, ih[ifile][0], ih[ifile][1], date, verbose=False)\n        if hdf is None:\n            continue\n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        sz = m[list(m.keys())[0]].shape\n        ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n        xm = np.linspace(x0,x1,sz[0])\n        ym = np.linspace(y0,y1,sz[1])\n        xs=x[ok]; ys=y[ok]\n        print(f\"ih={ih[ifile]} count={ok.sum()}\")\n        for key in m:\n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                if key+str(r) in out:\n                    v0 = out[key+str(r)][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                out[key+str(r)][ok] = v\n    bad = [key for key in out if np.isnan(out[key]).all()]\n    for key in bad:\n        out.pop(key)\n    if verbose:\n        print([date, {key: np.isfinite(out[key]).sum() for key in out}])\n    return out\n\n# hdf = getmodis_hv('MOD10A1', 8,4,datetime(2003,6,10))\n# m,x0,x1,y0,y1 = calibrate(hdf, keys=['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI'])\ndef getfields(product, date, h, v, out={}, verbose=False, keys=keys):\n    hdf = getmodis_hv(product, h, v, date, verbose=verbose)\n    if hdf is not None:        \n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        out['corners'] = x0,x1,y0,y1\n        for key in m:            \n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            if key in out:\n                out[key] += fld; out[key+'_c'] += ex\n            else:\n                out[key]  = fld; out[key+'_c']  = ex\n            print(f\"{product} {date} {h}_{v} {key} {fld.sum()/ex.sum():.4}\")\n    return out\n\ndef getmeanfields(reqdates, reqdays, loaddates, keys=keys, out = {}):\n    reqdays = [d.replace('-','_') for d in reqdays]    \n    for ifile in range(ih.shape[0]):\n        hvstr = f'f_{ih[ifile][0]}_{ih[ifile][1]}_'\n        for date in loaddates:\n            read = False\n            for date1,tday1 in zip (reqdates, reqdays):\n                if np.abs(((date-date1).days+180)%365-180)<=14:\n                    read = True\n                    break\n            if read:\n                ret = [getfields(product, date, ih[ifile][0], ih[ifile][1], keys=keys) \n                       for product in ['MOD10A1', 'MYD10A1'][:1+(date>=datetime(2002,7,4))]]\n                ret = {key: np.nanmean([r[key] for r in ret if len(r)>0],0) for key in keys+['corners']}\n                for date1,tday1 in zip (reqdates, reqdays):\n                    if np.abs(((date-date1).days+180)%365-180)<=14:\n                        for key in ret:\n                            if key != 'corners':\n                                name = hvstr+tday1+'M'+key\n                                if name in out:\n                                    out[name] = out[name]+ret[key]\n                                else:\n                                    out[name] = ret[key].copy()\n                                # if np.isnan(out[name]).any():\n                                #     print(f\"{name} bads={np.isnan(out[name]).sum()} goods={np.isfinite(out[name]).sum()}\")\n                                # else:\n                                if name[-2:] == '_c':\n                                    print(f\"{name[:-2]} {(out[name[:-2]]/out[name]).mean():.4}\")\n                            elif hvstr+key not in out:\n                                out[hvstr+key] = ret[key]\n    for key in out:\n        if key+'_c' in out:\n            out[key] = out[key]/out[key+'_c']\n    for key in [k for k in out.keys() if k[-2:]=='_c']:\n        out.pop(key)\n    return out\n\ndef interpfields(arx, df, reqdates, reqdays, rads, verbose=False, keys=keys):\n    x, y = sinu(df['longitude'].values, df['latitude'].values)\n    for key in arx:\n        if key[-7:] != 'corners':\n            hvstr = '_'.join(key.split('_')[:3])+'_'\n            x0,x1,y0,y1 = arx[hvstr+'corners']\n            sz = arx[key].shape\n            ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n            xm = np.linspace(x0,x1,sz[0])\n            ym = np.linspace(y0,y1,sz[1])\n            xs=x[ok]; ys=y[ok]\n            print(f\"{key} count={ok.sum()}\")\n            ex = np.isfinite(arx[key]).astype(np.float32)\n            fld = np.nan_to_num(arx[key],0.)\n            key1 = key[len(hvstr):]\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                name = key1[:10].replace('_','-')+key1[10:]+str(r)\n                if name in df:\n                    v0 = df[name][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                else:\n                    df[name] = np.full_like(x, np.nan)\n                df[name][ok] = v\n    return df\n\nif __name__ == '__main__':\n    # import geojson\n    # import pandas as pd\n    # from os import path\n    # workdir = 'evaluation'\n    # # workdir = 'development'\n    # with open(path.join(workdir,'grid_cells.geojson')) as f:\n    #     grid = geojson.load(f)\n    # grid = pd.DataFrame([{'cell_id':g['properties']['cell_id'], 'region':g['properties']['region'], \n    #                       'corners': np.array(g['geometry']['coordinates'])} for g in grid['features']]).set_index('cell_id')\n    # gll = np.vstack(grid['corners'].values)    \n    # grid['latitude'] = gll[:,:,1].mean(1)\n    # grid['longitude'] = gll[:,:,0].mean(1)\n    # stmeta = pd.read_csv(path.join(workdir,'ground_measures_metadata.csv')).set_index('station_id')\n    \n    import matplotlib.pyplot as plt\n    file = getmodis_lat_lon('MYD10A1', 41.881832, -87.623177, datetime(2010, 5, 15))\n    print(list(file.datasets().keys()))    \n    rgb,x0,x1,y0,y1 = calibrate(file)\n    for key in rgb:\n        fig = plt.figure(frameon=False); ax = plt.Axes(fig,[0., 0., 1., 1.])\n        ax.set_axis_off(); fig.add_axes(ax)\n        plt.imshow(rgb[key])\n        ax.set_title(key)",
  "history_output" : "Traceback (most recent call last):\n  File \"data_modis.py\", line 1, in <module>\n    from azure.storage.blob import ContainerClient\nImportError: cannot import name 'ContainerClient' from 'azure.storage.blob' (/Users/uhhmed/env_snowcast/lib/python3.8/site-packages/azure/storage/blob/__init__.py)\n",
  "history_begin_time" : 1667948917033,
  "history_end_time" : 1667948917533,
  "history_notes" : null,
  "history_process" : "mxd0ok",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "4lvR3jFNgQU1",
  "history_input" : "from azure.storage.blob import ContainerClient\nimport cv2\nfrom datetime import datetime, timedelta\nimport numpy as np\nimport os\nfrom pyhdf.SD import SD, SDC\nfrom pyproj import Proj,transform\nimport re\nfrom scipy.interpolate import interp2d\nimport wget\n\nclass ModisSource:\n    modis_account_name = 'modissa'\n    modis_container_name = 'modis-006'\n    modis_account_url = 'https://' + modis_account_name + '.blob.core.windows.net/'\n    modis_blob_root = modis_account_url + modis_container_name + '/'\n        \n    temp_dir = os.environ['MODISPATH']\n    if not os.path.isdir(temp_dir):\n        import tempfile\n        temp_dir = os.path.join(tempfile.gettempdir(),'modis')\n        os.makedirs(temp_dir,exist_ok=True)\n    tempfiles = os.listdir(temp_dir)\n    \n    print(f\"data\\\\modis.py: Modis dir is {temp_dir} contain {len(tempfiles)} files\")\n\n    fname = 'sn_bound_10deg.txt'\n    fn = os.path.join(temp_dir, fname)\n    if not os.path.isfile(fn):\n        wget.download(modis_blob_root + fname, fn)\n    \n    # Load this file into a table, where each row is (v,h,lonmin,lonmax,latmin,latmax)\n    modis_tile_extents = np.genfromtxt(fn, skip_header = 7, skip_footer = 3)\n    modis_container_client = ContainerClient(account_url=modis_account_url, \n                                             container_name=modis_container_name,\n                                             credential=None)\n    \ndef lat_lon_to_modis_tiles(lat,lon):\n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    return ModisSource.modis_tile_extents[ok.nonzero()[0], 1::-1].astype(np.int64)\ndef lat_lon_to_modis_tile(lat,lon):\n    \"\"\"\n    Get the modis tile indices (h,v) for a given lat/lon    \n    https://www.earthdatascience.org/tutorials/convert-modis-tile-to-lat-lon/\n    \"\"\"    \n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    i = ok.nonzero()[0]\n    i = i[1] if len(i) >=3 else i[-1]\n    return int(ModisSource.modis_tile_extents[i, 1]),int(ModisSource.modis_tile_extents[i, 0])\n\ndef list_blobs_in_folder(container_name,folder_name):\n    generator = ModisSource.modis_container_client.list_blobs(name_starts_with=folder_name)\n    return [blob.name for blob in generator]\n            \ndef list_hdf_blobs_in_folder(container_name,folder_name):\n    files = list_blobs_in_folder(container_name,folder_name)\n    return [fn for fn in files if fn.endswith('.hdf')]\n\nul_regex = re.compile(r'''UpperLeftPointMtrs=\\(\n                          (?P<upper_left_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<upper_left_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\nlr_regex = re.compile(r'''LowerRightMtrs=\\(\n                          (?P<lower_right_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<lower_right_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\n\n# keys = ['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI']\n# keys = ['NDSI_Snow_Cover', 'NDSI']\nkeys = ['NDSI_Snow_Cover']\nqakey = 'NDSI_Snow_Cover_Basic_QA'\n\ndef calibrate(hdf, keys=None):\n    ga = hdf.attributes()['StructMetadata.0']\n    match = ul_regex.search(ga)\n    x0 = float(match.group('upper_left_x'))\n    y0 = float(match.group('upper_left_y'))\n    match = lr_regex.search(ga)\n    x1 = float(match.group('lower_right_x'))\n    y1 = float(match.group('lower_right_y'))\n    out = {}\n    for key in hdf.datasets():\n        if keys is not None:\n            if key not in keys and key != qakey:\n                continue\n        f = hdf.select(key)\n        data = f.get()\n        attr = f.attributes()    \n        # print(attr)\n        data_c = data.astype(np.float32)\n        if 'scale_factor' in attr:\n            data_c = data_c * float(attr['scale_factor'])            \n        if '_FillValue' in attr:\n            data_c[data==attr['_FillValue']] = np.nan\n        if 'valid_range' in attr:\n            valid_range = attr['valid_range']\n            data_c = np.minimum(np.maximum(data_c, valid_range[0]), valid_range[1])\n        out[key] = data_c\n    qa = out[qakey]==4\n    out['NDSI_Snow_Cover'][qa] = np.nan\n    if qakey not in keys:\n        out.pop(qakey)\n    return out,x0,x1,y0,y1\n    \ndef getmodis_hv(product, h, v, date, verbose=True):\n    # Files are stored according to:\n    # http://modissa.blob.core.windows.net/modis-006/[product]/[htile]/[vtile]/[year][day]/filename\n    # This is the MODIS surface reflectance product\n    folder = product + '/' + '{:0>2d}/{:0>2d}'.format(h,v) + '/' + date.strftime('%Y%j')\n    # Find all HDF files from this tile on this day    \n    # filename = folder+'/'+product+'.A'+date.strftime('%Y%j')+'.h{:0>2d}v{:0>2d}'.format(h,v)+'.006'+\n    filename = folder.replace('/','_')\n    filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    if len(filenames) == 0:\n        ModisSource.tempfiles = os.listdir(ModisSource.temp_dir)\n        filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    ex = False\n    if len(filenames) > 0:        \n        filename = os.path.join(ModisSource.temp_dir,filenames[0])\n        ex = os.path.isfile(filename)\n    if not ex:\n        filenames = list_hdf_blobs_in_folder(ModisSource.modis_container_name,folder)\n        if verbose:\n            print('Found {} matching file(s):'.format(len(filenames)))\n            for fn in filenames:\n                print(fn)    \n        if len(filenames) == 0:\n            return None\n        filename = os.path.join(ModisSource.temp_dir, filenames[0].replace('/','_'))\n        print(filename)\n        if not os.path.isfile(filename):\n            # Download to a temporary file\n            wget.download(ModisSource.modis_blob_root + filenames[0], filename)\n    return SD(filename, SDC.READ)\n\ndef getmodis_lat_lon(product, lat, lon, date, verbose=True):\n    h,v = lat_lon_to_modis_tile(lat,lon)\n    return getmodis_hv(product, h, v, date, verbose)\n\nrgauss = 2.0\ndef getaver (lon,lat,lons,lats,elev,ex,r):\n    ry = r/(1110./(lat.shape[0]-1))\n    mask = (2*int(rgauss*ry)+1, 2*int(rgauss*ry)+1)\n    av = np.nan_to_num(cv2.GaussianBlur(elev, mask, ry)/cv2.GaussianBlur(ex, mask, ry),-9999.)\n    f = interp2d(lon, lat, av, kind='linear')\n    ret = np.array([f(lons[k], lats[k])[0] for k in range(lons.shape[0])])\n    ret[ret<0.] = np.nan\n    return ret\n\nsinu = Proj('+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs')\n# wgs84 = Proj(\"+init=EPSG:4326\")\n# ih = np.array([[8,4],[8,5],[9,4],[9,5],[10,4]])\nih = np.array([[9,5],[8,4],[8,5],[9,4],[10,4]])\ndef getinterpolated(product, lat, lon, date, rads, verbose=False, keys=keys, new=True):    \n    out = {}\n    if keys is not None:\n        if new:\n            for r in rads:\n                out.update({key+str(r): np.full_like(lat, np.nan) for key in keys})\n        else:\n            out.update({key: np.full_like(lat, np.nan) for key in keys})\n    # x, y = transform(wgs84, sinu, lon, lat)\n    x, y = sinu(lon, lat)\n    ihs = [lat_lon_to_modis_tiles(latk,lonk) for lonk,latk in zip(lon,lat)]\n    ih = np.unique(np.concatenate (ihs,0), axis=0)\n    # badhv = np.array([[7,5],[8,4],[11,4]])    \n    for ifile in range(ih.shape[0]):\n        hdf = getmodis_hv(product, ih[ifile][0], ih[ifile][1], date, verbose=False)\n        if hdf is None:\n            continue\n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        sz = m[list(m.keys())[0]].shape\n        ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n        xm = np.linspace(x0,x1,sz[0])\n        ym = np.linspace(y0,y1,sz[1])\n        xs=x[ok]; ys=y[ok]\n        print(f\"ih={ih[ifile]} count={ok.sum()}\")\n        for key in m:\n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                if key+str(r) in out:\n                    v0 = out[key+str(r)][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                out[key+str(r)][ok] = v\n    bad = [key for key in out if np.isnan(out[key]).all()]\n    for key in bad:\n        out.pop(key)\n    if verbose:\n        print([date, {key: np.isfinite(out[key]).sum() for key in out}])\n    return out\n\n# hdf = getmodis_hv('MOD10A1', 8,4,datetime(2003,6,10))\n# m,x0,x1,y0,y1 = calibrate(hdf, keys=['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI'])\ndef getfields(product, date, h, v, out={}, verbose=False, keys=keys):\n    hdf = getmodis_hv(product, h, v, date, verbose=verbose)\n    if hdf is not None:        \n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        out['corners'] = x0,x1,y0,y1\n        for key in m:            \n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            if key in out:\n                out[key] += fld; out[key+'_c'] += ex\n            else:\n                out[key]  = fld; out[key+'_c']  = ex\n            print(f\"{product} {date} {h}_{v} {key} {fld.sum()/ex.sum():.4}\")\n    return out\n\ndef getmeanfields(reqdates, reqdays, loaddates, keys=keys, out = {}):\n    reqdays = [d.replace('-','_') for d in reqdays]    \n    for ifile in range(ih.shape[0]):\n        hvstr = f'f_{ih[ifile][0]}_{ih[ifile][1]}_'\n        for date in loaddates:\n            read = False\n            for date1,tday1 in zip (reqdates, reqdays):\n                if np.abs(((date-date1).days+180)%365-180)<=14:\n                    read = True\n                    break\n            if read:\n                ret = [getfields(product, date, ih[ifile][0], ih[ifile][1], keys=keys) \n                       for product in ['MOD10A1', 'MYD10A1'][:1+(date>=datetime(2002,7,4))]]\n                ret = {key: np.nanmean([r[key] for r in ret if len(r)>0],0) for key in keys+['corners']}\n                for date1,tday1 in zip (reqdates, reqdays):\n                    if np.abs(((date-date1).days+180)%365-180)<=14:\n                        for key in ret:\n                            if key != 'corners':\n                                name = hvstr+tday1+'M'+key\n                                if name in out:\n                                    out[name] = out[name]+ret[key]\n                                else:\n                                    out[name] = ret[key].copy()\n                                # if np.isnan(out[name]).any():\n                                #     print(f\"{name} bads={np.isnan(out[name]).sum()} goods={np.isfinite(out[name]).sum()}\")\n                                # else:\n                                if name[-2:] == '_c':\n                                    print(f\"{name[:-2]} {(out[name[:-2]]/out[name]).mean():.4}\")\n                            elif hvstr+key not in out:\n                                out[hvstr+key] = ret[key]\n    for key in out:\n        if key+'_c' in out:\n            out[key] = out[key]/out[key+'_c']\n    for key in [k for k in out.keys() if k[-2:]=='_c']:\n        out.pop(key)\n    return out\n\ndef interpfields(arx, df, reqdates, reqdays, rads, verbose=False, keys=keys):\n    x, y = sinu(df['longitude'].values, df['latitude'].values)\n    for key in arx:\n        if key[-7:] != 'corners':\n            hvstr = '_'.join(key.split('_')[:3])+'_'\n            x0,x1,y0,y1 = arx[hvstr+'corners']\n            sz = arx[key].shape\n            ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n            xm = np.linspace(x0,x1,sz[0])\n            ym = np.linspace(y0,y1,sz[1])\n            xs=x[ok]; ys=y[ok]\n            print(f\"{key} count={ok.sum()}\")\n            ex = np.isfinite(arx[key]).astype(np.float32)\n            fld = np.nan_to_num(arx[key],0.)\n            key1 = key[len(hvstr):]\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                name = key1[:10].replace('_','-')+key1[10:]+str(r)\n                if name in df:\n                    v0 = df[name][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                else:\n                    df[name] = np.full_like(x, np.nan)\n                df[name][ok] = v\n    return df\n\nif __name__ == '__main__':\n    # import geojson\n    # import pandas as pd\n    # from os import path\n    # workdir = 'evaluation'\n    # # workdir = 'development'\n    # with open(path.join(workdir,'grid_cells.geojson')) as f:\n    #     grid = geojson.load(f)\n    # grid = pd.DataFrame([{'cell_id':g['properties']['cell_id'], 'region':g['properties']['region'], \n    #                       'corners': np.array(g['geometry']['coordinates'])} for g in grid['features']]).set_index('cell_id')\n    # gll = np.vstack(grid['corners'].values)    \n    # grid['latitude'] = gll[:,:,1].mean(1)\n    # grid['longitude'] = gll[:,:,0].mean(1)\n    # stmeta = pd.read_csv(path.join(workdir,'ground_measures_metadata.csv')).set_index('station_id')\n    \n    import matplotlib.pyplot as plt\n    file = getmodis_lat_lon('MYD10A1', 41.881832, -87.623177, datetime(2010, 5, 15))\n    print(list(file.datasets().keys()))    \n    rgb,x0,x1,y0,y1 = calibrate(file)\n    for key in rgb:\n        fig = plt.figure(frameon=False); ax = plt.Axes(fig,[0., 0., 1., 1.])\n        ax.set_axis_off(); fig.add_axes(ax)\n        plt.imshow(rgb[key])\n        ax.set_title(key)",
  "history_output" : "Traceback (most recent call last):\n  File \"data_modis.py\", line 1, in <module>\n    from azure.storage.blob import ContainerClient\nModuleNotFoundError: No module named 'azure'\n",
  "history_begin_time" : 1667948811298,
  "history_end_time" : 1667948811478,
  "history_notes" : null,
  "history_process" : "mxd0ok",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "ryQvYQ9exTlF",
  "history_input" : "from azure.storage.blob import ContainerClient\nimport cv2\nfrom datetime import datetime, timedelta\nimport numpy as np\nimport os\nfrom pyhdf.SD import SD, SDC\nfrom pyproj import Proj,transform\nimport re\nfrom scipy.interpolate import interp2d\nimport wget\n\nclass ModisSource:\n    modis_account_name = 'modissa'\n    modis_container_name = 'modis-006'\n    modis_account_url = 'https://' + modis_account_name + '.blob.core.windows.net/'\n    modis_blob_root = modis_account_url + modis_container_name + '/'\n        \n    temp_dir = os.environ['MODISPATH']\n    if not os.path.isdir(temp_dir):\n        import tempfile\n        temp_dir = os.path.join(tempfile.gettempdir(),'modis')\n        os.makedirs(temp_dir,exist_ok=True)\n    tempfiles = os.listdir(temp_dir)\n    \n    print(f\"data\\\\modis.py: Modis dir is {temp_dir} contain {len(tempfiles)} files\")\n\n    fname = 'sn_bound_10deg.txt'\n    fn = os.path.join(temp_dir, fname)\n    if not os.path.isfile(fn):\n        wget.download(modis_blob_root + fname, fn)\n    \n    # Load this file into a table, where each row is (v,h,lonmin,lonmax,latmin,latmax)\n    modis_tile_extents = np.genfromtxt(fn, skip_header = 7, skip_footer = 3)\n    modis_container_client = ContainerClient(account_url=modis_account_url, \n                                             container_name=modis_container_name,\n                                             credential=None)\n    \ndef lat_lon_to_modis_tiles(lat,lon):\n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    return ModisSource.modis_tile_extents[ok.nonzero()[0], 1::-1].astype(np.int64)\ndef lat_lon_to_modis_tile(lat,lon):\n    \"\"\"\n    Get the modis tile indices (h,v) for a given lat/lon    \n    https://www.earthdatascience.org/tutorials/convert-modis-tile-to-lat-lon/\n    \"\"\"    \n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    i = ok.nonzero()[0]\n    i = i[1] if len(i) >=3 else i[-1]\n    return int(ModisSource.modis_tile_extents[i, 1]),int(ModisSource.modis_tile_extents[i, 0])\n\ndef list_blobs_in_folder(container_name,folder_name):\n    generator = ModisSource.modis_container_client.list_blobs(name_starts_with=folder_name)\n    return [blob.name for blob in generator]\n            \ndef list_hdf_blobs_in_folder(container_name,folder_name):\n    files = list_blobs_in_folder(container_name,folder_name)\n    return [fn for fn in files if fn.endswith('.hdf')]\n\nul_regex = re.compile(r'''UpperLeftPointMtrs=\\(\n                          (?P<upper_left_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<upper_left_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\nlr_regex = re.compile(r'''LowerRightMtrs=\\(\n                          (?P<lower_right_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<lower_right_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\n\n# keys = ['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI']\n# keys = ['NDSI_Snow_Cover', 'NDSI']\nkeys = ['NDSI_Snow_Cover']\nqakey = 'NDSI_Snow_Cover_Basic_QA'\n\ndef calibrate(hdf, keys=None):\n    ga = hdf.attributes()['StructMetadata.0']\n    match = ul_regex.search(ga)\n    x0 = float(match.group('upper_left_x'))\n    y0 = float(match.group('upper_left_y'))\n    match = lr_regex.search(ga)\n    x1 = float(match.group('lower_right_x'))\n    y1 = float(match.group('lower_right_y'))\n    out = {}\n    for key in hdf.datasets():\n        if keys is not None:\n            if key not in keys and key != qakey:\n                continue\n        f = hdf.select(key)\n        data = f.get()\n        attr = f.attributes()    \n        # print(attr)\n        data_c = data.astype(np.float32)\n        if 'scale_factor' in attr:\n            data_c = data_c * float(attr['scale_factor'])            \n        if '_FillValue' in attr:\n            data_c[data==attr['_FillValue']] = np.nan\n        if 'valid_range' in attr:\n            valid_range = attr['valid_range']\n            data_c = np.minimum(np.maximum(data_c, valid_range[0]), valid_range[1])\n        out[key] = data_c\n    qa = out[qakey]==4\n    out['NDSI_Snow_Cover'][qa] = np.nan\n    if qakey not in keys:\n        out.pop(qakey)\n    return out,x0,x1,y0,y1\n    \ndef getmodis_hv(product, h, v, date, verbose=True):\n    # Files are stored according to:\n    # http://modissa.blob.core.windows.net/modis-006/[product]/[htile]/[vtile]/[year][day]/filename\n    # This is the MODIS surface reflectance product\n    folder = product + '/' + '{:0>2d}/{:0>2d}'.format(h,v) + '/' + date.strftime('%Y%j')\n    # Find all HDF files from this tile on this day    \n    # filename = folder+'/'+product+'.A'+date.strftime('%Y%j')+'.h{:0>2d}v{:0>2d}'.format(h,v)+'.006'+\n    filename = folder.replace('/','_')\n    filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    if len(filenames) == 0:\n        ModisSource.tempfiles = os.listdir(ModisSource.temp_dir)\n        filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    ex = False\n    if len(filenames) > 0:        \n        filename = os.path.join(ModisSource.temp_dir,filenames[0])\n        ex = os.path.isfile(filename)\n    if not ex:\n        filenames = list_hdf_blobs_in_folder(ModisSource.modis_container_name,folder)\n        if verbose:\n            print('Found {} matching file(s):'.format(len(filenames)))\n            for fn in filenames:\n                print(fn)    \n        if len(filenames) == 0:\n            return None\n        filename = os.path.join(ModisSource.temp_dir, filenames[0].replace('/','_'))\n        print(filename)\n        if not os.path.isfile(filename):\n            # Download to a temporary file\n            wget.download(ModisSource.modis_blob_root + filenames[0], filename)\n    return SD(filename, SDC.READ)\n\ndef getmodis_lat_lon(product, lat, lon, date, verbose=True):\n    h,v = lat_lon_to_modis_tile(lat,lon)\n    return getmodis_hv(product, h, v, date, verbose)\n\nrgauss = 2.0\ndef getaver (lon,lat,lons,lats,elev,ex,r):\n    ry = r/(1110./(lat.shape[0]-1))\n    mask = (2*int(rgauss*ry)+1, 2*int(rgauss*ry)+1)\n    av = np.nan_to_num(cv2.GaussianBlur(elev, mask, ry)/cv2.GaussianBlur(ex, mask, ry),-9999.)\n    f = interp2d(lon, lat, av, kind='linear')\n    ret = np.array([f(lons[k], lats[k])[0] for k in range(lons.shape[0])])\n    ret[ret<0.] = np.nan\n    return ret\n\nsinu = Proj('+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs')\n# wgs84 = Proj(\"+init=EPSG:4326\")\n# ih = np.array([[8,4],[8,5],[9,4],[9,5],[10,4]])\nih = np.array([[9,5],[8,4],[8,5],[9,4],[10,4]])\ndef getinterpolated(product, lat, lon, date, rads, verbose=False, keys=keys, new=True):    \n    out = {}\n    if keys is not None:\n        if new:\n            for r in rads:\n                out.update({key+str(r): np.full_like(lat, np.nan) for key in keys})\n        else:\n            out.update({key: np.full_like(lat, np.nan) for key in keys})\n    # x, y = transform(wgs84, sinu, lon, lat)\n    x, y = sinu(lon, lat)\n    ihs = [lat_lon_to_modis_tiles(latk,lonk) for lonk,latk in zip(lon,lat)]\n    ih = np.unique(np.concatenate (ihs,0), axis=0)\n    # badhv = np.array([[7,5],[8,4],[11,4]])    \n    for ifile in range(ih.shape[0]):\n        hdf = getmodis_hv(product, ih[ifile][0], ih[ifile][1], date, verbose=False)\n        if hdf is None:\n            continue\n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        sz = m[list(m.keys())[0]].shape\n        ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n        xm = np.linspace(x0,x1,sz[0])\n        ym = np.linspace(y0,y1,sz[1])\n        xs=x[ok]; ys=y[ok]\n        print(f\"ih={ih[ifile]} count={ok.sum()}\")\n        for key in m:\n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                if key+str(r) in out:\n                    v0 = out[key+str(r)][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                out[key+str(r)][ok] = v\n    bad = [key for key in out if np.isnan(out[key]).all()]\n    for key in bad:\n        out.pop(key)\n    if verbose:\n        print([date, {key: np.isfinite(out[key]).sum() for key in out}])\n    return out\n\n# hdf = getmodis_hv('MOD10A1', 8,4,datetime(2003,6,10))\n# m,x0,x1,y0,y1 = calibrate(hdf, keys=['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI'])\ndef getfields(product, date, h, v, out={}, verbose=False, keys=keys):\n    hdf = getmodis_hv(product, h, v, date, verbose=verbose)\n    if hdf is not None:        \n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        out['corners'] = x0,x1,y0,y1\n        for key in m:            \n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            if key in out:\n                out[key] += fld; out[key+'_c'] += ex\n            else:\n                out[key]  = fld; out[key+'_c']  = ex\n            print(f\"{product} {date} {h}_{v} {key} {fld.sum()/ex.sum():.4}\")\n    return out\n\ndef getmeanfields(reqdates, reqdays, loaddates, keys=keys, out = {}):\n    reqdays = [d.replace('-','_') for d in reqdays]    \n    for ifile in range(ih.shape[0]):\n        hvstr = f'f_{ih[ifile][0]}_{ih[ifile][1]}_'\n        for date in loaddates:\n            read = False\n            for date1,tday1 in zip (reqdates, reqdays):\n                if np.abs(((date-date1).days+180)%365-180)<=14:\n                    read = True\n                    break\n            if read:\n                ret = [getfields(product, date, ih[ifile][0], ih[ifile][1], keys=keys) \n                       for product in ['MOD10A1', 'MYD10A1'][:1+(date>=datetime(2002,7,4))]]\n                ret = {key: np.nanmean([r[key] for r in ret if len(r)>0],0) for key in keys+['corners']}\n                for date1,tday1 in zip (reqdates, reqdays):\n                    if np.abs(((date-date1).days+180)%365-180)<=14:\n                        for key in ret:\n                            if key != 'corners':\n                                name = hvstr+tday1+'M'+key\n                                if name in out:\n                                    out[name] = out[name]+ret[key]\n                                else:\n                                    out[name] = ret[key].copy()\n                                # if np.isnan(out[name]).any():\n                                #     print(f\"{name} bads={np.isnan(out[name]).sum()} goods={np.isfinite(out[name]).sum()}\")\n                                # else:\n                                if name[-2:] == '_c':\n                                    print(f\"{name[:-2]} {(out[name[:-2]]/out[name]).mean():.4}\")\n                            elif hvstr+key not in out:\n                                out[hvstr+key] = ret[key]\n    for key in out:\n        if key+'_c' in out:\n            out[key] = out[key]/out[key+'_c']\n    for key in [k for k in out.keys() if k[-2:]=='_c']:\n        out.pop(key)\n    return out\n\ndef interpfields(arx, df, reqdates, reqdays, rads, verbose=False, keys=keys):\n    x, y = sinu(df['longitude'].values, df['latitude'].values)\n    for key in arx:\n        if key[-7:] != 'corners':\n            hvstr = '_'.join(key.split('_')[:3])+'_'\n            x0,x1,y0,y1 = arx[hvstr+'corners']\n            sz = arx[key].shape\n            ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n            xm = np.linspace(x0,x1,sz[0])\n            ym = np.linspace(y0,y1,sz[1])\n            xs=x[ok]; ys=y[ok]\n            print(f\"{key} count={ok.sum()}\")\n            ex = np.isfinite(arx[key]).astype(np.float32)\n            fld = np.nan_to_num(arx[key],0.)\n            key1 = key[len(hvstr):]\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                name = key1[:10].replace('_','-')+key1[10:]+str(r)\n                if name in df:\n                    v0 = df[name][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                else:\n                    df[name] = np.full_like(x, np.nan)\n                df[name][ok] = v\n    return df\n\nif __name__ == '__main__':\n    # import geojson\n    # import pandas as pd\n    # from os import path\n    # workdir = 'evaluation'\n    # # workdir = 'development'\n    # with open(path.join(workdir,'grid_cells.geojson')) as f:\n    #     grid = geojson.load(f)\n    # grid = pd.DataFrame([{'cell_id':g['properties']['cell_id'], 'region':g['properties']['region'], \n    #                       'corners': np.array(g['geometry']['coordinates'])} for g in grid['features']]).set_index('cell_id')\n    # gll = np.vstack(grid['corners'].values)    \n    # grid['latitude'] = gll[:,:,1].mean(1)\n    # grid['longitude'] = gll[:,:,0].mean(1)\n    # stmeta = pd.read_csv(path.join(workdir,'ground_measures_metadata.csv')).set_index('station_id')\n    \n    import matplotlib.pyplot as plt\n    file = getmodis_lat_lon('MYD10A1', 41.881832, -87.623177, datetime(2010, 5, 15))\n    print(list(file.datasets().keys()))    \n    rgb,x0,x1,y0,y1 = calibrate(file)\n    for key in rgb:\n        fig = plt.figure(frameon=False); ax = plt.Axes(fig,[0., 0., 1., 1.])\n        ax.set_axis_off(); fig.add_axes(ax)\n        plt.imshow(rgb[key])\n        ax.set_title(key)",
  "history_output" : "Traceback (most recent call last):\n  File \"data_modis.py\", line 1, in <module>\n    from azure.storage.blob import ContainerClient\nImportError: cannot import name 'ContainerClient' from 'azure.storage.blob' (/opt/anaconda3/lib/python3.8/site-packages/azure/storage/blob/__init__.py)\n",
  "history_begin_time" : 1667947809814,
  "history_end_time" : 1667947811005,
  "history_notes" : null,
  "history_process" : "mxd0ok",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "BR8bzJNh0ruN",
  "history_input" : "from azure.storage.blob import ContainerClient\nimport cv2\nfrom datetime import datetime, timedelta\nimport numpy as np\nimport os\nfrom pyhdf.SD import SD, SDC\nfrom pyproj import Proj,transform\nimport re\nfrom scipy.interpolate import interp2d\nimport wget\n\nclass ModisSource:\n    modis_account_name = 'modissa'\n    modis_container_name = 'modis-006'\n    modis_account_url = 'https://' + modis_account_name + '.blob.core.windows.net/'\n    modis_blob_root = modis_account_url + modis_container_name + '/'\n        \n    temp_dir = os.environ['MODISPATH']\n    if not os.path.isdir(temp_dir):\n        import tempfile\n        temp_dir = os.path.join(tempfile.gettempdir(),'modis')\n        os.makedirs(temp_dir,exist_ok=True)\n    tempfiles = os.listdir(temp_dir)\n    \n    print(f\"data\\\\modis.py: Modis dir is {temp_dir} contain {len(tempfiles)} files\")\n\n    fname = 'sn_bound_10deg.txt'\n    fn = os.path.join(temp_dir, fname)\n    if not os.path.isfile(fn):\n        wget.download(modis_blob_root + fname, fn)\n    \n    # Load this file into a table, where each row is (v,h,lonmin,lonmax,latmin,latmax)\n    modis_tile_extents = np.genfromtxt(fn, skip_header = 7, skip_footer = 3)\n    modis_container_client = ContainerClient(account_url=modis_account_url, \n                                             container_name=modis_container_name,\n                                             credential=None)\n    \ndef lat_lon_to_modis_tiles(lat,lon):\n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    return ModisSource.modis_tile_extents[ok.nonzero()[0], 1::-1].astype(np.int64)\ndef lat_lon_to_modis_tile(lat,lon):\n    \"\"\"\n    Get the modis tile indices (h,v) for a given lat/lon    \n    https://www.earthdatascience.org/tutorials/convert-modis-tile-to-lat-lon/\n    \"\"\"    \n    ok = (lat >= ModisSource.modis_tile_extents[:, 4]) & (lat <= ModisSource.modis_tile_extents[:, 5]) \\\n         & (lon >= ModisSource.modis_tile_extents[:, 2]) & (lon <= ModisSource.modis_tile_extents[:, 3])\n    i = ok.nonzero()[0]\n    i = i[1] if len(i) >=3 else i[-1]\n    return int(ModisSource.modis_tile_extents[i, 1]),int(ModisSource.modis_tile_extents[i, 0])\n\ndef list_blobs_in_folder(container_name,folder_name):\n    generator = ModisSource.modis_container_client.list_blobs(name_starts_with=folder_name)\n    return [blob.name for blob in generator]\n            \ndef list_hdf_blobs_in_folder(container_name,folder_name):\n    files = list_blobs_in_folder(container_name,folder_name)\n    return [fn for fn in files if fn.endswith('.hdf')]\n\nul_regex = re.compile(r'''UpperLeftPointMtrs=\\(\n                          (?P<upper_left_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<upper_left_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\nlr_regex = re.compile(r'''LowerRightMtrs=\\(\n                          (?P<lower_right_x>[+-]?\\d+\\.\\d+)\n                          ,\n                          (?P<lower_right_y>[+-]?\\d+\\.\\d+)\n                          \\)''', re.VERBOSE)\n\n# keys = ['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI']\n# keys = ['NDSI_Snow_Cover', 'NDSI']\nkeys = ['NDSI_Snow_Cover']\nqakey = 'NDSI_Snow_Cover_Basic_QA'\n\ndef calibrate(hdf, keys=None):\n    ga = hdf.attributes()['StructMetadata.0']\n    match = ul_regex.search(ga)\n    x0 = float(match.group('upper_left_x'))\n    y0 = float(match.group('upper_left_y'))\n    match = lr_regex.search(ga)\n    x1 = float(match.group('lower_right_x'))\n    y1 = float(match.group('lower_right_y'))\n    out = {}\n    for key in hdf.datasets():\n        if keys is not None:\n            if key not in keys and key != qakey:\n                continue\n        f = hdf.select(key)\n        data = f.get()\n        attr = f.attributes()    \n        # print(attr)\n        data_c = data.astype(np.float32)\n        if 'scale_factor' in attr:\n            data_c = data_c * float(attr['scale_factor'])            \n        if '_FillValue' in attr:\n            data_c[data==attr['_FillValue']] = np.nan\n        if 'valid_range' in attr:\n            valid_range = attr['valid_range']\n            data_c = np.minimum(np.maximum(data_c, valid_range[0]), valid_range[1])\n        out[key] = data_c\n    qa = out[qakey]==4\n    out['NDSI_Snow_Cover'][qa] = np.nan\n    if qakey not in keys:\n        out.pop(qakey)\n    return out,x0,x1,y0,y1\n    \ndef getmodis_hv(product, h, v, date, verbose=True):\n    # Files are stored according to:\n    # http://modissa.blob.core.windows.net/modis-006/[product]/[htile]/[vtile]/[year][day]/filename\n    # This is the MODIS surface reflectance product\n    folder = product + '/' + '{:0>2d}/{:0>2d}'.format(h,v) + '/' + date.strftime('%Y%j')\n    # Find all HDF files from this tile on this day    \n    # filename = folder+'/'+product+'.A'+date.strftime('%Y%j')+'.h{:0>2d}v{:0>2d}'.format(h,v)+'.006'+\n    filename = folder.replace('/','_')\n    filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    if len(filenames) == 0:\n        ModisSource.tempfiles = os.listdir(ModisSource.temp_dir)\n        filenames = [f for f in ModisSource.tempfiles if f[:len(filename)]==filename]\n    ex = False\n    if len(filenames) > 0:        \n        filename = os.path.join(ModisSource.temp_dir,filenames[0])\n        ex = os.path.isfile(filename)\n    if not ex:\n        filenames = list_hdf_blobs_in_folder(ModisSource.modis_container_name,folder)\n        if verbose:\n            print('Found {} matching file(s):'.format(len(filenames)))\n            for fn in filenames:\n                print(fn)    \n        if len(filenames) == 0:\n            return None\n        filename = os.path.join(ModisSource.temp_dir, filenames[0].replace('/','_'))\n        print(filename)\n        if not os.path.isfile(filename):\n            # Download to a temporary file\n            wget.download(ModisSource.modis_blob_root + filenames[0], filename)\n    return SD(filename, SDC.READ)\n\ndef getmodis_lat_lon(product, lat, lon, date, verbose=True):\n    h,v = lat_lon_to_modis_tile(lat,lon)\n    return getmodis_hv(product, h, v, date, verbose)\n\nrgauss = 2.0\ndef getaver (lon,lat,lons,lats,elev,ex,r):\n    ry = r/(1110./(lat.shape[0]-1))\n    mask = (2*int(rgauss*ry)+1, 2*int(rgauss*ry)+1)\n    av = np.nan_to_num(cv2.GaussianBlur(elev, mask, ry)/cv2.GaussianBlur(ex, mask, ry),-9999.)\n    f = interp2d(lon, lat, av, kind='linear')\n    ret = np.array([f(lons[k], lats[k])[0] for k in range(lons.shape[0])])\n    ret[ret<0.] = np.nan\n    return ret\n\nsinu = Proj('+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs')\n# wgs84 = Proj(\"+init=EPSG:4326\")\n# ih = np.array([[8,4],[8,5],[9,4],[9,5],[10,4]])\nih = np.array([[9,5],[8,4],[8,5],[9,4],[10,4]])\ndef getinterpolated(product, lat, lon, date, rads, verbose=False, keys=keys, new=True):    \n    out = {}\n    if keys is not None:\n        if new:\n            for r in rads:\n                out.update({key+str(r): np.full_like(lat, np.nan) for key in keys})\n        else:\n            out.update({key: np.full_like(lat, np.nan) for key in keys})\n    # x, y = transform(wgs84, sinu, lon, lat)\n    x, y = sinu(lon, lat)\n    ihs = [lat_lon_to_modis_tiles(latk,lonk) for lonk,latk in zip(lon,lat)]\n    ih = np.unique(np.concatenate (ihs,0), axis=0)\n    # badhv = np.array([[7,5],[8,4],[11,4]])    \n    for ifile in range(ih.shape[0]):\n        hdf = getmodis_hv(product, ih[ifile][0], ih[ifile][1], date, verbose=False)\n        if hdf is None:\n            continue\n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        sz = m[list(m.keys())[0]].shape\n        ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n        xm = np.linspace(x0,x1,sz[0])\n        ym = np.linspace(y0,y1,sz[1])\n        xs=x[ok]; ys=y[ok]\n        print(f\"ih={ih[ifile]} count={ok.sum()}\")\n        for key in m:\n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                if key+str(r) in out:\n                    v0 = out[key+str(r)][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                out[key+str(r)][ok] = v\n    bad = [key for key in out if np.isnan(out[key]).all()]\n    for key in bad:\n        out.pop(key)\n    if verbose:\n        print([date, {key: np.isfinite(out[key]).sum() for key in out}])\n    return out\n\n# hdf = getmodis_hv('MOD10A1', 8,4,datetime(2003,6,10))\n# m,x0,x1,y0,y1 = calibrate(hdf, keys=['NDSI_Snow_Cover', 'NDSI_Snow_Cover_Basic_QA', 'NDSI'])\ndef getfields(product, date, h, v, out={}, verbose=False, keys=keys):\n    hdf = getmodis_hv(product, h, v, date, verbose=verbose)\n    if hdf is not None:        \n        m,x0,x1,y0,y1 = calibrate(hdf, keys=keys)\n        out['corners'] = x0,x1,y0,y1\n        for key in m:            \n            ex = np.isfinite(m[key]).astype(np.float32)\n            fld = np.nan_to_num(m[key],0.)\n            if key in out:\n                out[key] += fld; out[key+'_c'] += ex\n            else:\n                out[key]  = fld; out[key+'_c']  = ex\n            print(f\"{product} {date} {h}_{v} {key} {fld.sum()/ex.sum():.4}\")\n    return out\n\ndef getmeanfields(reqdates, reqdays, loaddates, keys=keys, out = {}):\n    reqdays = [d.replace('-','_') for d in reqdays]    \n    for ifile in range(ih.shape[0]):\n        hvstr = f'f_{ih[ifile][0]}_{ih[ifile][1]}_'\n        for date in loaddates:\n            read = False\n            for date1,tday1 in zip (reqdates, reqdays):\n                if np.abs(((date-date1).days+180)%365-180)<=14:\n                    read = True\n                    break\n            if read:\n                ret = [getfields(product, date, ih[ifile][0], ih[ifile][1], keys=keys) \n                       for product in ['MOD10A1', 'MYD10A1'][:1+(date>=datetime(2002,7,4))]]\n                ret = {key: np.nanmean([r[key] for r in ret if len(r)>0],0) for key in keys+['corners']}\n                for date1,tday1 in zip (reqdates, reqdays):\n                    if np.abs(((date-date1).days+180)%365-180)<=14:\n                        for key in ret:\n                            if key != 'corners':\n                                name = hvstr+tday1+'M'+key\n                                if name in out:\n                                    out[name] = out[name]+ret[key]\n                                else:\n                                    out[name] = ret[key].copy()\n                                # if np.isnan(out[name]).any():\n                                #     print(f\"{name} bads={np.isnan(out[name]).sum()} goods={np.isfinite(out[name]).sum()}\")\n                                # else:\n                                if name[-2:] == '_c':\n                                    print(f\"{name[:-2]} {(out[name[:-2]]/out[name]).mean():.4}\")\n                            elif hvstr+key not in out:\n                                out[hvstr+key] = ret[key]\n    for key in out:\n        if key+'_c' in out:\n            out[key] = out[key]/out[key+'_c']\n    for key in [k for k in out.keys() if k[-2:]=='_c']:\n        out.pop(key)\n    return out\n\ndef interpfields(arx, df, reqdates, reqdays, rads, verbose=False, keys=keys):\n    x, y = sinu(df['longitude'].values, df['latitude'].values)\n    for key in arx:\n        if key[-7:] != 'corners':\n            hvstr = '_'.join(key.split('_')[:3])+'_'\n            x0,x1,y0,y1 = arx[hvstr+'corners']\n            sz = arx[key].shape\n            ok = (x<=x1) & (y>=y1) & (x>=x0) & (y<=y0) \n            xm = np.linspace(x0,x1,sz[0])\n            ym = np.linspace(y0,y1,sz[1])\n            xs=x[ok]; ys=y[ok]\n            print(f\"{key} count={ok.sum()}\")\n            ex = np.isfinite(arx[key]).astype(np.float32)\n            fld = np.nan_to_num(arx[key],0.)\n            key1 = key[len(hvstr):]\n            for r in rads:\n                v = getaver (xm,ym,xs,ys,fld,ex,r)\n                name = key1[:10].replace('_','-')+key1[10:]+str(r)\n                if name in df:\n                    v0 = df[name][ok]\n                    vi = np.isnan(v)\n                    v[vi] = v0[vi]\n                else:\n                    df[name] = np.full_like(x, np.nan)\n                df[name][ok] = v\n    return df\n\nif __name__ == '__main__':\n    # import geojson\n    # import pandas as pd\n    # from os import path\n    # workdir = 'evaluation'\n    # # workdir = 'development'\n    # with open(path.join(workdir,'grid_cells.geojson')) as f:\n    #     grid = geojson.load(f)\n    # grid = pd.DataFrame([{'cell_id':g['properties']['cell_id'], 'region':g['properties']['region'], \n    #                       'corners': np.array(g['geometry']['coordinates'])} for g in grid['features']]).set_index('cell_id')\n    # gll = np.vstack(grid['corners'].values)    \n    # grid['latitude'] = gll[:,:,1].mean(1)\n    # grid['longitude'] = gll[:,:,0].mean(1)\n    # stmeta = pd.read_csv(path.join(workdir,'ground_measures_metadata.csv')).set_index('station_id')\n    \n    import matplotlib.pyplot as plt\n    file = getmodis_lat_lon('MYD10A1', 41.881832, -87.623177, datetime(2010, 5, 15))\n    print(list(file.datasets().keys()))    \n    rgb,x0,x1,y0,y1 = calibrate(file)\n    for key in rgb:\n        fig = plt.figure(frameon=False); ax = plt.Axes(fig,[0., 0., 1., 1.])\n        ax.set_axis_off(); fig.add_axes(ax)\n        plt.imshow(rgb[key])\n        ax.set_title(key)",
  "history_output" : "Traceback (most recent call last):\n  File \"data_modis.py\", line 1, in <module>\n    from azure.storage.blob import ContainerClient\nModuleNotFoundError: No module named 'azure'\n",
  "history_begin_time" : 1667947664210,
  "history_end_time" : 1667947664375,
  "history_notes" : null,
  "history_process" : "mxd0ok",
  "host_id" : null,
  "indicator" : "Failed"
},]
